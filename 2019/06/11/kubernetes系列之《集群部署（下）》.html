<!DOCTYPE html>












  


<html class="theme-next mist use-motion" lang="zh-CN">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2"/>
<meta name="theme-color" content="#222">

<script src="//cdn.bootcss.com/pace/1.0.2/pace.min.js"></script>
<link href="//cdn.bootcss.com/pace/1.0.2/themes/pink/pace-theme-flash.css" rel="stylesheet">
<style>
    .pace .pace-progress {
        background: #1E92FB; /*进度条颜色*/
        height: 3px;
    }
    .pace .pace-progress-inner {
         box-shadow: 0 0 10px #1E92FB, 0 0 5px     #1E92FB; /*阴影颜色*/
    }
    .pace .pace-activity {
        border-top-color: #1E92FB;    /*上边框颜色*/
        border-left-color: #1E92FB;    /*左边框颜色*/
    }
</style>











<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />






















<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=6.3.0" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.3.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.3.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.3.0">


  <link rel="mask-icon" href="/images/logo.svg?v=6.3.0" color="#222">









<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '6.3.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: false,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="本文继承上一篇文章《集群部署（上）》, 继续Kubernetes集群实战本文将实现：  完整部署一套Kubernetes 部署Kubernetes UI（Dashboard） 部署多Master节点的Kubernetes集群 部署Kubernetes集群内部DNS（CoreDNS ）">
<meta name="keywords" content="Kubernetes,etcd,flanneld,SSL,Docker">
<meta property="og:type" content="article">
<meta property="og:title" content="kubernetes系列之《集群部署（下）》.md">
<meta property="og:url" content="//blog.nicksors.cc/2019/06/11/kubernetes系列之《集群部署（下）》.html">
<meta property="og:site_name" content="开元DevOps知识库">
<meta property="og:description" content="本文继承上一篇文章《集群部署（上）》, 继续Kubernetes集群实战本文将实现：  完整部署一套Kubernetes 部署Kubernetes UI（Dashboard） 部署多Master节点的Kubernetes集群 部署Kubernetes集群内部DNS（CoreDNS ）">
<meta property="og:locale" content="zh-CN">
<meta property="og:updated_time" content="2019-06-26T09:11:21.546Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="kubernetes系列之《集群部署（下）》.md">
<meta name="twitter:description" content="本文继承上一篇文章《集群部署（上）》, 继续Kubernetes集群实战本文将实现：  完整部署一套Kubernetes 部署Kubernetes UI（Dashboard） 部署多Master节点的Kubernetes集群 部署Kubernetes集群内部DNS（CoreDNS ）">






  <link rel="canonical" href="//blog.nicksors.cc/2019/06/11/kubernetes系列之《集群部署（下）》.html"/>



<script type="text/javascript" id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>kubernetes系列之《集群部署（下）》.md | 开元DevOps知识库</title>
  









  <noscript>
  <style type="text/css">
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion {
      .logo-line-before i { left: initial; }
      .logo-line-after i { right: initial; }
    }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>
<a href="https://github.com/nicksors"><img style="position: absolute; top: 0; right: 0; border: 0;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_orange_ff7600.png" alt="Fork me on GitHub"></a>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">开元DevOps知识库</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">没有白走的路，每一步都算数.</p>
      
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">
    <a href="/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-home"></i> <br />首页</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">
    <a href="/tags/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />标签</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-categories">
    <a href="/categories/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-th"></i> <br />分类</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">
    <a href="/archives/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />归档</a>
  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />搜索</a>
        </li>
      
    </ul>
  

  
    

  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



  



</div>
    </header>

    


    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="//blog.nicksors.cc/2019/06/11/kubernetes系列之《集群部署（下）》.html">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="开元">
      <meta itemprop="description" content="知识管理，时间管理，自我管理">
      <meta itemprop="image" content="/static/images/stark.jpg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="开元DevOps知识库">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">kubernetes系列之《集群部署（下）》.md
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2019-06-11 14:18:22" itemprop="dateCreated datePublished" datetime="2019-06-11T14:18:22+08:00">2019-06-11</time>
            

            
              

              
                
                <span class="post-meta-divider">|</span>
                

                <span class="post-meta-item-icon">
                  <i class="fa fa-calendar-check-o"></i>
                </span>
                
                  <span class="post-meta-item-text">更新于</span>
                
                <time title="修改时间：2019-06-26 17:11:21" itemprop="dateModified" datetime="2019-06-26T17:11:21+08:00">2019-06-26</time>
              
            
          </span>

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/kubernetes/" itemprop="url" rel="index"><span itemprop="name">kubernetes</span></a></span>

                
                
              
            </span>
          

          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <blockquote>
<p>本文继承上一篇文章《集群部署（上）》, 继续Kubernetes集群实战<br>本文将实现：</p>
<ol>
<li>完整部署一套Kubernetes</li>
<li>部署Kubernetes UI（Dashboard）</li>
<li>部署多Master节点的Kubernetes集群</li>
<li>部署Kubernetes集群内部DNS（CoreDNS ）<a id="more"></a>
</li>
</ol>
</blockquote>
<h2 id="七、部署Master组件"><a href="#七、部署Master组件" class="headerlink" title="七、部署Master组件"></a>七、部署Master组件</h2><p>根据环境规划，Master节点应有以下组件：</p>
<ul>
<li>kube-apiserver</li>
<li>kube-controller-manager</li>
<li>kube-sheduler</li>
<li>etcd</li>
</ul>
<p>etcd在上面已经部署完成，本文里Master节点是k8s-master-128，那该节点就剩下其他三个组件需部署。</p>
<h3 id="7-1、获取二进制包"><a href="#7-1、获取二进制包" class="headerlink" title="7.1、获取二进制包"></a>7.1、获取二进制包</h3><p>官网：<a href="https://kubernetes.io/，" target="_blank" rel="noopener">https://kubernetes.io/，</a><br>Github: <a href="https://github.com/kubernetes/kubernetes/releases" target="_blank" rel="noopener">https://github.com/kubernetes/kubernetes/releases</a><br>二进制包：<a href="https://dl.k8s.io/v1.14.0/kubernetes-server-linux-amd64.tar.gz" target="_blank" rel="noopener">https://dl.k8s.io/v1.14.0/kubernetes-server-linux-amd64.tar.gz</a></p>
<p>注意：二进制包比较大，400M大小，且有墙，我这里手动下载然后上传到服务器；</p>
<h3 id="7-2、部署二进制文件"><a href="#7-2、部署二进制文件" class="headerlink" title="7.2、部署二进制文件"></a>7.2、部署二进制文件</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"># 部署Master组件</span><br><span class="line">[root@k8s-master-128 ~]# cd soft/</span><br><span class="line">[root@k8s-master-128 soft]# tar zxf kubernetes-server-linux-amd64.tar.gz</span><br><span class="line">[root@k8s-master-128 soft]# cp kubernetes/server/bin/&#123;kubectl,kube-scheduler,kube-controller-manager,kube-apiserver&#125; /opt/kubernetes/bin/</span><br><span class="line">[root@k8s-master-128 soft]# echo &quot;export PATH=$PATH:/opt/kubernetes/bin&quot; &gt;&gt;/etc/profile</span><br><span class="line">[root@k8s-master-128 soft]# source /etc/profile</span><br><span class="line">[root@k8s-master-128 soft]# which kubectl</span><br><span class="line">/opt/kubernetes/bin/kubectl</span><br><span class="line"></span><br><span class="line"># 部署Node组件（方便后面使用）</span><br><span class="line">[root@k8s-master-128 soft]# scp kubernetes/server/bin/&#123;kubelet,kube-proxy&#125; k8s-node-129:/opt/kubernetes/bin/</span><br></pre></td></tr></table></figure>
<h3 id="7-3、生成Kubeconfig文件"><a href="#7-3、生成Kubeconfig文件" class="headerlink" title="7.3、生成Kubeconfig文件"></a>7.3、生成Kubeconfig文件</h3><h4 id="7-3-1、api-server认证方式"><a href="#7-3-1、api-server认证方式" class="headerlink" title="7.3.1、api-server认证方式"></a>7.3.1、api-server认证方式</h4><p>这个是知识了解，api-server有如下几种认证方式：</p>
<ol>
<li>CA证书认证</li>
<li>Token认证：token-auth</li>
<li>基本认证：basic-auth</li>
</ol>
<p>kubernetes 认证主要分为上面三种，可以同时配置多种认证方式，只要其中任意一个方式认证通过即可。</p>
<p><strong>参考：</strong></p>
<ul>
<li><a href="https://www.kubernetes.org.cn/1995.html" target="_blank" rel="noopener">Kubernetes 的安全机制 APIServer 认证、授权、准入控制</a></li>
<li><a href="https://www.jianshu.com/p/97a3e7060f4c" target="_blank" rel="noopener">Kubernetes apiserver认证</a></li>
</ul>
<p>本次部署使用第二种：Token认证。</p>
<h4 id="7-3-2、创建配置文件"><a href="#7-3-2、创建配置文件" class="headerlink" title="7.3.2、创建配置文件"></a>7.3.2、创建配置文件</h4><p>需要创建以下三个配置文件。</p>
<ul>
<li>1、创建TLS Bootstrapping Token</li>
<li>2、创建kubelet kubeconfig</li>
<li>3、创建kube-proxy kubeconfig</li>
</ul>
<p>我们使用一个脚本将所有的配置文件一起创建出来<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-128 ~]# mkdir ssl/k8s-cret</span><br><span class="line">[root@k8s-master-128 ~]# cd ssl/k8s-cret/</span><br><span class="line">[root@k8s-master-128 k8s-cret]# vim kubeconfig.sh</span><br><span class="line"># 创建 TLS Bootstrapping Token</span><br><span class="line">export BOOTSTRAP_TOKEN=$(head -c 16 /dev/urandom | od -An -t x | tr -d &apos; &apos;) # 生成随机token（随机字符串）</span><br><span class="line"></span><br><span class="line">cat &gt; token.csv &lt;&lt;EOF</span><br><span class="line">$&#123;BOOTSTRAP_TOKEN&#125;,kubelet-bootstrap,10001,&quot;system:kubelet-bootstrap&quot;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">#----------------------</span><br><span class="line"># 创建kubelet bootstrapping kubeconfig</span><br><span class="line">export KUBE_APISERVER=&quot;https://172.16.194.128:6443&quot; # 这个脚本唯一需要更改的就是这个地方，填写成你的Master IP地址</span><br><span class="line"></span><br><span class="line"># 设置集群参数</span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">  --certificate-authority=./ca.pem \</span><br><span class="line">  --embed-certs=true \</span><br><span class="line">  --server=$&#123;KUBE_APISERVER&#125; \</span><br><span class="line">  --kubeconfig=bootstrap.kubeconfig</span><br><span class="line"></span><br><span class="line"># 设置客户端认证参数</span><br><span class="line">kubectl config set-credentials kubelet-bootstrap \</span><br><span class="line">  --token=$&#123;BOOTSTRAP_TOKEN&#125; \</span><br><span class="line">  --kubeconfig=bootstrap.kubeconfig</span><br><span class="line"></span><br><span class="line"># 设置上下文参数</span><br><span class="line">kubectl config set-context default \</span><br><span class="line">  --cluster=kubernetes \</span><br><span class="line">  --user=kubelet-bootstrap \</span><br><span class="line">  --kubeconfig=bootstrap.kubeconfig</span><br><span class="line"></span><br><span class="line"># 设置默认上下文</span><br><span class="line">kubectl config use-context default --kubeconfig=bootstrap.kubeconfig</span><br><span class="line">#----------------------</span><br><span class="line"></span><br><span class="line"># 创建kube-proxy kubeconfig文件</span><br><span class="line">kubectl config set-cluster kubernetes \</span><br><span class="line">  --certificate-authority=./ca.pem \</span><br><span class="line">  --embed-certs=true \</span><br><span class="line">  --server=$&#123;KUBE_APISERVER&#125; \</span><br><span class="line">  --kubeconfig=kube-proxy.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-credentials kube-proxy \</span><br><span class="line">  --client-certificate=./kube-proxy.pem \</span><br><span class="line">  --client-key=./kube-proxy-key.pem \</span><br><span class="line">  --embed-certs=true \</span><br><span class="line">  --kubeconfig=kube-proxy.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config set-context default \</span><br><span class="line">  --cluster=kubernetes \</span><br><span class="line">  --user=kube-proxy \</span><br><span class="line">  --kubeconfig=kube-proxy.kubeconfig</span><br><span class="line"></span><br><span class="line">kubectl config use-context default --kubeconfig=kube-proxy.kubeconfig</span><br></pre></td></tr></table></figure></p>
<p>执行脚本，创建配置文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-128 k8s-cret]# chmod +x kubeconfig.sh</span><br><span class="line">[root@k8s-master-128 k8s-cret]# ./kubeconfig.sh</span><br><span class="line">Cluster &quot;kubernetes&quot; set.</span><br><span class="line">User &quot;kubelet-bootstrap&quot; set.</span><br><span class="line">Context &quot;default&quot; created.</span><br><span class="line">Switched to context &quot;default&quot;.</span><br><span class="line">Cluster &quot;kubernetes&quot; set.</span><br><span class="line">User &quot;kube-proxy&quot; set.</span><br><span class="line">Context &quot;default&quot; created.</span><br><span class="line">Switched to context &quot;default&quot;.</span><br></pre></td></tr></table></figure></p>
<p><strong>配置文件的用途：</strong> 总共创建了三个文件，用途分别为：</p>
<ul>
<li>bootstrap.kubeconfig # Node节点的kubelet组件使用</li>
<li>kube-proxy.kubeconfig # Node节点的kube-proxy组件使用</li>
<li>token.csv # Master节点的apiserver组件使用</li>
</ul>
<p>根据上面的用途说明，将生成的文件推送到各个节点的目录中（以备后面部署组件使用）：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># Master节点只需要token.csv</span><br><span class="line">[root@k8s-master-128 k8s-cret]# cp token.csv /opt/kubernetes/cfg/</span><br><span class="line"></span><br><span class="line"># Node节点推送文件</span><br><span class="line">[root@k8s-master-128 k8s-cret]# scp bootstrap.kubeconfig kube-proxy.kubeconfig k8s-node-129:/opt/kubernetes/cfg/</span><br><span class="line">[root@k8s-master-128 k8s-cret]# scp bootstrap.kubeconfig kube-proxy.kubeconfig k8s-node-130:/opt/kubernetes/cfg/</span><br></pre></td></tr></table></figure></p>
<h4 id="7-3-3、查看配置文件"><a href="#7-3-3、查看配置文件" class="headerlink" title="7.3.3、查看配置文件"></a>7.3.3、查看配置文件</h4><p>token.csv</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-128 k8s-cret]# cat token.csv</span><br><span class="line">38435b41e3861251dce8c2cbf968ca67,kubelet-bootstrap,10001,&quot;system:kubelet-bootstrap&quot;</span><br></pre></td></tr></table></figure>
<p>注解：</p>
<ul>
<li>38435b41e3861251dce8c2cbf968ca67：随机生成的token，也可以固定一个Token来使用</li>
<li>kubelet-bootstrap ：用户名</li>
<li>10001：用户ID</li>
<li>system:kubelet-bootstrap：用户组</li>
</ul>
<p>bootstrap.kubeconfig<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-128 k8s-cret]# cat bootstrap.kubeconfig</span><br><span class="line">apiVersion: v1 # api的版本</span><br><span class="line">clusters: # 集群的内容</span><br><span class="line">- cluster:</span><br><span class="line">    certificate-authority-data:   # 集群CA数字证书，有很大一堆，略······</span><br><span class="line">    server: https://172.16.194.128:6443 # server的地址</span><br><span class="line">  name: kubernetes # 集群的名字</span><br><span class="line">contexts: # 上下文内容</span><br><span class="line">- context:</span><br><span class="line">    cluster: kubernetes</span><br><span class="line">    user: kubelet-bootstrap # k8s用户（可改变，是从token.csv里定义的）</span><br><span class="line">  name: default # 上下文名称</span><br><span class="line">current-context: default # 当前默认使用的上下文</span><br><span class="line">kind: Config</span><br><span class="line">preferences: &#123;&#125;</span><br><span class="line">users:  # 用户的信息</span><br><span class="line">- name: kubelet-bootstrap # 用户名</span><br><span class="line">  user:</span><br><span class="line">    token: 38435b41e3861251dce8c2cbf968ca67  # token，关键！必须要与token.csv里的token对应！不对应则没有相应的权限，会认证失败。</span><br></pre></td></tr></table></figure></p>
<p>kube-proxy.kubeconfig<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-128 k8s-cret]# cat kube-proxy.kubeconfig</span><br><span class="line">apiVersion: v1</span><br><span class="line">clusters:</span><br><span class="line">- cluster:</span><br><span class="line">    certificate-authority-data:  # 集群CA数字证书，有很大一堆，略······</span><br><span class="line">    server: https://192.16.194.128:6443</span><br><span class="line">  name: kubernetes</span><br><span class="line">contexts:</span><br><span class="line">- context:</span><br><span class="line">    cluster: kubernetes</span><br><span class="line">    user: kube-proxy</span><br><span class="line">  name: default</span><br><span class="line">current-context: default</span><br><span class="line">kind: Config</span><br><span class="line">preferences: &#123;&#125;</span><br><span class="line">users:</span><br><span class="line">- name: kube-proxy</span><br><span class="line">  user:</span><br><span class="line">    client-certificate-data: # 客户端CA数字证书，有很大一堆，略······</span><br><span class="line">    client-key-data: # 客户端key证书，有很大一堆，略······</span><br></pre></td></tr></table></figure></p>
<h3 id="7-4、启动Master组件"><a href="#7-4、启动Master组件" class="headerlink" title="7.4、启动Master组件"></a>7.4、启动Master组件</h3><h4 id="7-4-1、启动kube-apiserver"><a href="#7-4-1、启动kube-apiserver" class="headerlink" title="7.4.1、启动kube-apiserver"></a>7.4.1、启动kube-apiserver</h4><p><strong>1、启动的脚本</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-128 ~]# cat apiserver.sh </span><br><span class="line">#!/bin/bash</span><br><span class="line">MASTER_ADDRESS=$&#123;1:-&quot;192.168.1.195&quot;&#125;</span><br><span class="line">ETCD_SERVERS=$&#123;2:-&quot;http://127.0.0.1:2379&quot;&#125;</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt;/opt/kubernetes/cfg/kube-apiserver</span><br><span class="line">KUBE_APISERVER_OPTS=&quot;--logtostderr=false \</span><br><span class="line">--log-dir=/opt/kubernetes/logs \</span><br><span class="line">--v=4 \</span><br><span class="line">--etcd-servers=$&#123;ETCD_SERVERS&#125; \</span><br><span class="line">--insecure-bind-address=127.0.0.1 \</span><br><span class="line">--bind-address=$&#123;MASTER_ADDRESS&#125; \</span><br><span class="line">--insecure-port=8080 \</span><br><span class="line">--secure-port=6443 \</span><br><span class="line">--advertise-address=$&#123;MASTER_ADDRESS&#125; \</span><br><span class="line">--allow-privileged=true \</span><br><span class="line">--service-cluster-ip-range=10.0.0.0/24 \</span><br><span class="line">--service-node-port-range=30000-50000 \</span><br><span class="line">--admission-control=NamespaceLifecycle,LimitRanger,SecurityContextDeny,ServiceAccount,ResourceQuota,NodeRestriction \</span><br><span class="line">--authorization-mode=RBAC,Node \</span><br><span class="line">--kubelet-https=true \</span><br><span class="line">--enable-bootstrap-token-auth \</span><br><span class="line">--token-auth-file=/opt/kubernetes/cfg/token.csv \</span><br><span class="line">--tls-cert-file=/opt/kubernetes/ssl/server.pem \</span><br><span class="line">--tls-private-key-file=/opt/kubernetes/ssl/server-key.pem \</span><br><span class="line">--client-ca-file=/opt/kubernetes/ssl/ca.pem \</span><br><span class="line">--service-account-key-file=/opt/kubernetes/ssl/ca-key.pem \</span><br><span class="line">--etcd-cafile=/opt/etcd/ssl/ca.pem \</span><br><span class="line">--etcd-certfile=/opt/etcd/ssl/server.pem \</span><br><span class="line">--etcd-keyfile=/opt/etcd/ssl/server-key.pem&quot;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt;/usr/lib/systemd/system/kube-apiserver.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes API Server</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=-/opt/kubernetes/cfg/kube-apiserver</span><br><span class="line">ExecStart=/opt/kubernetes/bin/kube-apiserver \$KUBE_APISERVER_OPTS</span><br><span class="line">Restart=on-failure</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></p>
<p><strong>2、启动apiserver</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"># apiserver.sh 接收两个参数，第一个是apiserver的地址，第二个是ETCD集群的地址，我们集群有三个节点，都填写上。</span><br><span class="line">[root@k8s-master-128 ~]# chmod +x apiserver.sh</span><br><span class="line">[root@k8s-master-128 ~]# ./apiserver.sh 172.16.194.128 https://172.16.194.128:2379,https://172.16.194.129:2379,https://172.16.194.130:2379</span><br><span class="line">[root@k8s-master-128 ~]# systemctl daemon-reload</span><br><span class="line">[root@k8s-master-128 ~]# systemctl enable kube-apiserver</span><br><span class="line">[root@k8s-master-128 ~]# systemctl start kube-apiserver</span><br><span class="line">[root@k8s-master-128 ~]# systemctl status kube-apiserver</span><br></pre></td></tr></table></figure></p>
<p><strong>3、查看启动状态</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-128 logs]# ls -lh /opt/kubernetes/logs/  # 详细日志</span><br><span class="line">[root@k8s-master-128 logs]# netstat -lntup|grep kube</span><br><span class="line">tcp 0 0 172.16.194.128:6443 0.0.0.0:* LISTEN 28201/kube-apiserve</span><br><span class="line">tcp 0 0 127.0.0.1:8080 0.0.0.0:* LISTEN 28201/kube-apiserve</span><br><span class="line">[root@k8s-master-128 logs]# ps -ef|grep kube-apiserver</span><br><span class="line"># 信息太多，不贴了</span><br></pre></td></tr></table></figure></p>
<p><strong>注意：</strong></p>
<ol>
<li>如果你照着上面的脚本执行后，如没有进程存活，你应该查看下日志和检查上面的证书都是否存在。</li>
<li>一定要先启动apiserver！因为后面两个组件依赖apiserver，controller-manager和scheduler可以没有先后顺序。</li>
</ol>
<h4 id="7-4-2、启动kube-controller-manager"><a href="#7-4-2、启动kube-controller-manager" class="headerlink" title="7.4.2、启动kube-controller-manager"></a>7.4.2、启动kube-controller-manager</h4><p><strong>1、启动的脚本</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-128 ~]# cat controller-manager.sh</span><br><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">MASTER_ADDRESS=$&#123;1:-&quot;127.0.0.1&quot;&#125;</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt;/opt/kubernetes/cfg/kube-controller-manager</span><br><span class="line">KUBE_CONTROLLER_MANAGER_OPTS=&quot;--logtostderr=false \</span><br><span class="line">--log-dir=/opt/kubernetes/logs \</span><br><span class="line">--v=4 \</span><br><span class="line">--master=$&#123;MASTER_ADDRESS&#125;:8080 \</span><br><span class="line">--leader-elect=true \</span><br><span class="line">--address=127.0.0.1 \</span><br><span class="line">--service-cluster-ip-range=10.0.0.0/24 \</span><br><span class="line">--cluster-name=kubernetes \</span><br><span class="line">--cluster-signing-cert-file=/opt/kubernetes/ssl/ca.pem \</span><br><span class="line">--cluster-signing-key-file=/opt/kubernetes/ssl/ca-key.pem \</span><br><span class="line">--root-ca-file=/opt/kubernetes/ssl/ca.pem \</span><br><span class="line">--service-account-private-key-file=/opt/kubernetes/ssl/ca-key.pem \</span><br><span class="line">--experimental-cluster-signing-duration=87600h0m0s&quot;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt;/usr/lib/systemd/system/kube-controller-manager.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Controller Manager</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=-/opt/kubernetes/cfg/kube-controller-manager</span><br><span class="line">ExecStart=/opt/kubernetes/bin/kube-controller-manager \$KUBE_CONTROLLER_MANAGER_OPTS</span><br><span class="line">Restart=on-failure</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></p>
<p><strong>2、启动controller-manager</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-128 ~]# chmod +x controller-manager.sh</span><br><span class="line">[root@k8s-master-128 ~]# ./controller-manager.sh</span><br><span class="line">[root@k8s-master-128 ~]# systemctl daemon-reload</span><br><span class="line">[root@k8s-master-128 ~]# systemctl enable kube-controller-manager</span><br><span class="line">[root@k8s-master-128 ~]# systemctl start kube-controller-manager</span><br></pre></td></tr></table></figure></p>
<p>启动失败请检查这两个文件是否配置正确，以及启动日志:<br>/opt/kubernetes/cfg/kube-controller-manager<br>/usr/lib/systemd/system/kube-controller-manager.service<br>/opt/kubernetes/logs/</p>
<p><strong>3、查看启动状态</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># controller-manager启动的端口是10252</span><br><span class="line">[root@k8s-master-128 ~]# netstat -lntup|grep kube-c</span><br><span class="line">tcp 0 0 127.0.0.1:10252 0.0.0.0:* LISTEN 7699/kube-controlle</span><br><span class="line">tcp6 0 0 :::10257 :::* LISTEN 7699/kube-controlle</span><br><span class="line">[root@k8s-master-128 ~]# ps -ef|grep controller-manager</span><br></pre></td></tr></table></figure></p>
<h4 id="7-4-3、启动kube-sheduler"><a href="#7-4-3、启动kube-sheduler" class="headerlink" title="7.4.3、启动kube-sheduler"></a>7.4.3、启动kube-sheduler</h4><p><strong>1、启动的脚本</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-128 ~]# cat scheduler.sh</span><br><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">MASTER_ADDRESS=$&#123;1:-&quot;127.0.0.1&quot;&#125;</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt;/opt/kubernetes/cfg/kube-scheduler</span><br><span class="line">KUBE_SCHEDULER_OPTS=&quot;--logtostderr=false \</span><br><span class="line">--log-dir=/opt/kubernetes/logs \</span><br><span class="line">--v=4 \</span><br><span class="line">--master=$&#123;MASTER_ADDRESS&#125;:8080 \</span><br><span class="line">--leader-elect&quot;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt;/usr/lib/systemd/system/kube-scheduler.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Scheduler</span><br><span class="line">Documentation=https://github.com/kubernetes/kubernetes</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=-/opt/kubernetes/cfg/kube-scheduler</span><br><span class="line">ExecStart=/opt/kubernetes/bin/kube-scheduler \$KUBE_SCHEDULER_OPTS</span><br><span class="line">Restart=on-failure</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></p>
<p><strong>2、启动scheduler</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-128 ~]# chmod +x scheduler.sh</span><br><span class="line">[root@k8s-master-128 ~]# ./scheduler.sh</span><br><span class="line">[root@k8s-master-128 ~]# systemctl daemon-reload</span><br><span class="line">[root@k8s-master-128 ~]# systemctl enable kube-scheduler</span><br><span class="line">[root@k8s-master-128 ~]# systemctl start kube-scheduler</span><br></pre></td></tr></table></figure></p>
<p><strong>3、查看启动状态</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># scheduler启动的端口是10251</span><br><span class="line">[root@k8s-master-128 ~]# netstat -lntup|grep kube-sc</span><br><span class="line">tcp6 0 0 :::10251 :::* LISTEN 7897/kube-scheduler</span><br><span class="line">tcp6 0 0 :::10259 :::* LISTEN 7897/kube-scheduler</span><br><span class="line">[root@k8s-master-128 ~]# ps -ef|grep scheduler</span><br></pre></td></tr></table></figure></p>
<h3 id="7-5、查看组件运行状态"><a href="#7-5、查看组件运行状态" class="headerlink" title="7.5、查看组件运行状态"></a>7.5、查看组件运行状态</h3><p>kubectl get cs # 查看k8s集群资源的健康信息<br>相关阅读：<a href="http://docs.kubernetes.org.cn/626.html" target="_blank" rel="noopener">Kubernetes kubectl get 命令详解</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-128 ~]# kubectl get cs</span><br><span class="line">NAME STATUS MESSAGE ERROR</span><br><span class="line">controller-manager Healthy ok</span><br><span class="line">scheduler Healthy ok</span><br><span class="line">etcd-1 Healthy &#123;&quot;health&quot;:&quot;true&quot;&#125;</span><br><span class="line">etcd-0 Healthy &#123;&quot;health&quot;:&quot;true&quot;&#125;</span><br><span class="line">etcd-2 Healthy &#123;&quot;health&quot;:&quot;true&quot;&#125;</span><br></pre></td></tr></table></figure></p>
<p><code>看到以上信息都为健康状态，到此，Kubernetes集群的Master节点即部署完成。</code></p>
<h2 id="八、部署Node组件"><a href="#八、部署Node组件" class="headerlink" title="八、部署Node组件"></a>八、部署Node组件</h2><p>根据前面环境规划，Node节点将启动kubelet和kube-proxy组件。</p>
<h3 id="8-1、创建Token租户并绑定角色"><a href="#8-1、创建Token租户并绑定角色" class="headerlink" title="8.1、创建Token租户并绑定角色"></a>8.1、创建Token租户并绑定角色</h3><p>这是我们创建的tuken信息，需要把租户信息创建出来，Node节点在部署kubelet组件时需要通过token租户进行权限验证<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-128 ~]# kubectl create --help</span><br><span class="line">[root@k8s-master-128 ~]# kubectl create clusterrolebinding --help</span><br><span class="line">Usage:</span><br><span class="line">  kubectl create clusterrolebinding NAME --clusterrole=NAME [--user=username] [--group=groupname]</span><br><span class="line">[--serviceaccount=namespace:serviceaccountname] [--dry-run] [options]</span><br><span class="line"></span><br><span class="line">[root@k8s-master-128 ~]# kubectl create clusterrolebinding kubelet-bootstrap --clusterrole=system:node-bootstrapper --user=kubelet-bootstrap</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/kubelet-bootstrap created</span><br><span class="line">[root@k8s-master-128 ~]# kubectl get clusterrole # 查看集群角色（system:node-bootstrapper由此得来）</span><br></pre></td></tr></table></figure></p>
<h3 id="8-2、部署Kubelet"><a href="#8-2、部署Kubelet" class="headerlink" title="8.2、部署Kubelet"></a>8.2、部署Kubelet</h3><h4 id="8-2-1、启动Kubelet组件"><a href="#8-2-1、启动Kubelet组件" class="headerlink" title="8.2.1、启动Kubelet组件"></a>8.2.1、启动Kubelet组件</h4><p><strong>1、启动的脚本</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-node-129 ~]# cat kubelet.sh</span><br><span class="line">#!/bin/bash</span><br><span class="line"></span><br><span class="line">NODE_ADDRESS=$&#123;1:-&quot;127.0.0.1&quot;&#125; # 节点的IP地址，通过参数传入</span><br><span class="line">DNS_SERVER_IP=$&#123;2:-&quot;10.0.0.2&quot;&#125; # DNS地址，在apiserver.sh里指定的地址端，可以写10.10.10.0/24段的任意IP</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt;/opt/kubernetes/cfg/kubelet</span><br><span class="line">KUBELET_OPTS=&quot;--logtostderr=false \</span><br><span class="line">--log-dir=/opt/kubernetes/logs \</span><br><span class="line">--v=4 \</span><br><span class="line">--address=$&#123;NODE_ADDRESS&#125; \</span><br><span class="line">--hostname-override=$&#123;NODE_ADDRESS&#125; \</span><br><span class="line">--kubeconfig=/opt/kubernetes/cfg/kubelet.kubeconfig \</span><br><span class="line">--experimental-bootstrap-kubeconfig=/opt/kubernetes/cfg/bootstrap.kubeconfig \</span><br><span class="line">--cert-dir=/opt/kubernetes/ssl \</span><br><span class="line">--allow-privileged=true \</span><br><span class="line">--cluster-dns=$&#123;DNS_SERVER_IP&#125; \</span><br><span class="line">--cluster-domain=cluster.local \</span><br><span class="line">--fail-swap-on=false \</span><br><span class="line">--pod-infra-container-image=registry.cn-hangzhou.aliyuncs.com/google-containers/pause-amd64:3.0&quot;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt;/usr/lib/systemd/system/kubelet.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Kubelet</span><br><span class="line">After=docker.service</span><br><span class="line">Requires=docker.service</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=-/opt/kubernetes/cfg/kubelet</span><br><span class="line">ExecStart=/opt/kubernetes/bin/kubelet \$KUBELET_OPTS</span><br><span class="line">Restart=on-failure</span><br><span class="line">KillMode=process</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></p>
<p><strong>2、启动kubelet</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"># 两个Node节点同时启动kubelet</span><br><span class="line">[root@k8s-node-129 ~]# chmod +x kubelet.sh</span><br><span class="line">[root@k8s-node-129 ~]# ./kubelet.sh 172.16.194.129</span><br><span class="line">[root@k8s-node-130 ~]# ./kubelet.sh 172.16.194.130</span><br><span class="line"></span><br><span class="line"># 启动kubelet</span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable kubelet</span><br><span class="line">systemctl start kubelet</span><br></pre></td></tr></table></figure></p>
<p><strong>3、查看启动状态</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-node-129 ~]# ps -ef|grep kubelet</span><br><span class="line">[root@k8s-node-129 ~]# ls -lh /opt/kubernetes/cfg/kubelet.kubeconfig</span><br><span class="line">ls: 无法访问/opt/kubernetes/cfg/kubelet.kubeconfig: 没有那个文件或目录</span><br></pre></td></tr></table></figure></p>
<p>注意：你会发现没有kubelet.kubeconfig文件，这是为什么呢？是因为k8s-Master需要给Node节点的kubelet组件颁发证书，Node节点才会生成这个证书文件。</p>
<p>承上，我们继续到Master节点看看证书请求状况:<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-128 ~]# kubectl get csr  # 查看Node节点的kubelet证书申请请求</span><br><span class="line">NAME AGE REQUESTOR CONDITION</span><br><span class="line">node-csr-K50rilZHx2Gn_MHesRDr_wIJ5hOrg3buFjWuq3RNRhE 3m45s kubelet-bootstrap Pending</span><br><span class="line">node-csr-xW7Q15gU-88wPvObRXmia6y-eMyx5dbcMHbGIwINzD0 15m kubelet-bootstrap Pending # 等待颁发状态</span><br></pre></td></tr></table></figure></p>
<h4 id="8-2-2、k8s集群为kubelet颁发证书"><a href="#8-2-2、k8s集群为kubelet颁发证书" class="headerlink" title="8.2.2、k8s集群为kubelet颁发证书"></a>8.2.2、k8s集群为kubelet颁发证书</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-128 ~]# kubectl --help|grep certificate</span><br><span class="line">  certificate 修改 certificate 资源.</span><br><span class="line">[root@k8s-master-128 ~]# kubectl certificate --help</span><br><span class="line">  approve 同意一个自签证书请求</span><br><span class="line">  deny 拒绝一个自签证书请求</span><br><span class="line"></span><br><span class="line">[root@k8s-master-128 ~]# kubectl certificate approve --help</span><br><span class="line">Usage:</span><br><span class="line">  kubectl certificate approve (-f FILENAME | NAME) [options]</span><br><span class="line"></span><br><span class="line"># 上面几步help我们找到了用法</span><br><span class="line">[root@k8s-master-128 ~]# kubectl certificate approve node-csr-K50rilZHx2Gn_MHesRDr_wIJ5hOrg3buFjWuq3RNRhE</span><br><span class="line">certificatesigningrequest.certificates.k8s.io/node-csr-K50rilZHx2Gn_MHesRDr_wIJ5hOrg3buFjWuq3RNRhE approved</span><br><span class="line">[root@k8s-master-128 ~]# kubectl certificate approve node-csr-xW7Q15gU-88wPvObRXmia6y-eMyx5dbcMHbGIwINzD0</span><br><span class="line">certificatesigningrequest.certificates.k8s.io/node-csr-xW7Q15gU-88wPvObRXmia6y-eMyx5dbcMHbGIwINzD0 approved</span><br><span class="line"></span><br><span class="line">[root@k8s-master-128 ~]# kubectl get csr</span><br><span class="line">NAME AGE REQUESTOR CONDITION</span><br><span class="line">node-csr-K50rilZHx2Gn_MHesRDr_wIJ5hOrg3buFjWuq3RNRhE 7m8s kubelet-bootstrap Approved,Issued</span><br><span class="line">node-csr-xW7Q15gU-88wPvObRXmia6y-eMyx5dbcMHbGIwINzD0 18m kubelet-bootstrap Approved,IssuedCRGvCskSEnG13F4BPrqQbDiR2epHRg4  7m        kubelet-bootstrap  Approved,Issued # 同意办法证书后，变为：批准状态。</span><br></pre></td></tr></table></figure>
<p>我这里有两个Node节点，都为其颁发证书允许加入集群。</p>
<h4 id="8-2-3、查看Node节点加入k8s集群"><a href="#8-2-3、查看Node节点加入k8s集群" class="headerlink" title="8.2.3、查看Node节点加入k8s集群"></a>8.2.3、查看Node节点加入k8s集群</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-128 ~]# kubectl get nodes  # 查看集群中的Node节点信息，Ready表示该节点健康，已准备就绪</span><br><span class="line">NAME STATUS ROLES AGE VERSION</span><br><span class="line">172.16.194.129 Ready &lt;none&gt; 54s v1.14.0</span><br><span class="line">172.16.194.130 Ready &lt;none&gt; 63s v1.14.0</span><br></pre></td></tr></table></figure>
<h4 id="8-2-4、查看Node节点签发的证书"><a href="#8-2-4、查看Node节点签发的证书" class="headerlink" title="8.2.4、查看Node节点签发的证书"></a>8.2.4、查看Node节点签发的证书</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-node-129 ~]# ls -lh /opt/kubernetes/cfg/kubelet.kubeconfig  # 已经有这个文件了，你可以cat查看内容细节</span><br><span class="line">-rw------- 1 root root 2.3K 5月 7 17:04 /opt/kubernetes/cfg/kubelet.kubeconfig</span><br><span class="line"></span><br><span class="line"># ssl目录生成如下证书</span><br><span class="line">[root@k8s-node-129 ~]# ls -lh /opt/kubernetes/ssl/kubelet*</span><br><span class="line">-rw------- 1 root root 1.3K 5月 7 17:04 /opt/kubernetes/ssl/kubelet-client-2019-05-07-17-04-27.pem</span><br><span class="line">lrwxrwxrwx 1 root root 58 5月 7 17:04 /opt/kubernetes/ssl/kubelet-client-current.pem -&gt; /opt/kubernetes/ssl/kubelet-client-2019-05-07-17-04-27.pem</span><br><span class="line">-rw-r--r-- 1 root root 2.2K 5月 7 16:36 /opt/kubernetes/ssl/kubelet.crt</span><br><span class="line">-rw------- 1 root root 1.7K 5月 7 16:36 /opt/kubernetes/ssl/kubelet.key</span><br></pre></td></tr></table></figure>
<p>整个自签发证书颁发流程完结。</p>
<h3 id="8-3、部署kube-proxy"><a href="#8-3、部署kube-proxy" class="headerlink" title="8.3、部署kube-proxy"></a>8.3、部署kube-proxy</h3><p><strong>1、启动的脚本</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-node-129 ~]# cat kube-proxy.sh</span><br><span class="line">#!/bin/bash</span><br><span class="line">NODE_ADDRESS=$&#123;1:-&quot;127.0.0.1&quot;&#125; # kube-proxy的节点IP</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt;/opt/kubernetes/cfg/kube-proxy</span><br><span class="line">KUBE_PROXY_OPTS=&quot;--logtostderr=false \</span><br><span class="line">--log-dir=/opt/kubernetes/logs \</span><br><span class="line">--v=4 \</span><br><span class="line">--hostname-override=$&#123;NODE_ADDRESS&#125; \</span><br><span class="line">--kubeconfig=/opt/kubernetes/cfg/kube-proxy.kubeconfig&quot;</span><br><span class="line">EOF</span><br><span class="line"></span><br><span class="line">cat &lt;&lt;EOF &gt;/usr/lib/systemd/system/kube-proxy.service</span><br><span class="line">[Unit]</span><br><span class="line">Description=Kubernetes Proxy</span><br><span class="line">After=network.target</span><br><span class="line"></span><br><span class="line">[Service]</span><br><span class="line">EnvironmentFile=-/opt/kubernetes/cfg/kube-proxy</span><br><span class="line">ExecStart=/opt/kubernetes/bin/kube-proxy \$KUBE_PROXY_OPTS</span><br><span class="line">Restart=on-failure</span><br><span class="line"></span><br><span class="line">[Install]</span><br><span class="line">WantedBy=multi-user.target</span><br><span class="line">EOF</span><br></pre></td></tr></table></figure></p>
<p><strong>2、启动kube-proxy</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"># 两个Node节点都启动kube-proxy</span><br><span class="line">[root@k8s-node-129 ~]# chmod +x kube-proxy.sh</span><br><span class="line"></span><br><span class="line">[root@k8s-node-129 ~]# ./kube-proxy.sh 172.16.194.129</span><br><span class="line">[root@k8s-node-130 ~]# ./kube-proxy.sh 172.16.194.130</span><br><span class="line"></span><br><span class="line"># 启动kube-proxy</span><br><span class="line">systemctl daemon-reload</span><br><span class="line">systemctl enable kube-proxy</span><br><span class="line">systemctl start kube-proxy</span><br></pre></td></tr></table></figure></p>
<p><strong>3、查看启动状态</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-node-129 ~]# ps -ef|grep kube-proxy</span><br><span class="line">[root@k8s-node-130 ~]# systemctl status kube-proxy</span><br></pre></td></tr></table></figure></p>
<h2 id="九、部署一个测试示例"><a href="#九、部署一个测试示例" class="headerlink" title="九、部署一个测试示例"></a>九、部署一个测试示例</h2><h3 id="9-1、创建一个Nginx-pods"><a href="#9-1、创建一个Nginx-pods" class="headerlink" title="9.1、创建一个Nginx pods"></a>9.1、创建一个Nginx pods</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-128 ~]# kubectl run --help  # 能看到有很多用法</span><br><span class="line">[root@k8s-master-128 ~]# kubectl run nginx --image=nginx</span><br><span class="line">[root@k8s-master-128 ~]# kubectl get pods</span><br><span class="line">NAME READY STATUS RESTARTS AGE</span><br><span class="line">nginx-7db9fccd9b-kckml 0/1 ContainerCreating 0 45s  # 第一次创建K8s会在Node节点上拉取镜像，启动时间稍长；</span><br><span class="line">[root@k8s-master-128 ~]# kubectl get pods</span><br><span class="line">NAME READY STATUS RESTARTS AGE</span><br><span class="line">nginx-7db9fccd9b-kckml 1/1 Running 0 3m57s</span><br></pre></td></tr></table></figure>
<p>查看pod被分配到了哪个节点上：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-128 ~]# kubectl get pod -o wide</span><br><span class="line">NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES</span><br><span class="line">nginx-7db9fccd9b-bhldc 1/1 Running 0 7m7s 172.17.64.2 172.16.194.129 &lt;none&gt; &lt;none&gt;</span><br></pre></td></tr></table></figure></p>
<h3 id="9-2、创建一个services"><a href="#9-2、创建一个services" class="headerlink" title="9.2、创建一个services"></a>9.2、创建一个services</h3><p>用于将pod封装成一个service，提供外界访问；<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-128 ~]# kubectl expose --help</span><br><span class="line">[root@k8s-master-128 ~]# kubectl expose deployment nginx --port=80 --target-port=80 --type=NodePort</span><br><span class="line">service/nginx exposed</span><br><span class="line">[root@k8s-master-128 ~]# kubectl get svc</span><br><span class="line">NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE</span><br><span class="line">kubernetes ClusterIP 10.0.0.1 &lt;none&gt; 443/TCP 22h</span><br><span class="line">nginx NodePort 10.0.0.86 &lt;none&gt; 80:43364/TCP 13s</span><br></pre></td></tr></table></figure></p>
<h3 id="9-3、访问services"><a href="#9-3、访问services" class="headerlink" title="9.3、访问services"></a>9.3、访问services</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-node-129 ~]# curl 10.0.0.86   # 对内访问</span><br><span class="line">[root@k8s-master-128 ~]# curl 172.16.194.129:43364  # 对外访问</span><br><span class="line"></span><br><span class="line"># 查看访问日志</span><br><span class="line">[root@k8s-master-128 ~]# kubectl get pods</span><br><span class="line">NAME READY STATUS RESTARTS AGE</span><br><span class="line">nginx-7db9fccd9b-bhldc 1/1 Running 0 13m</span><br><span class="line">[root@k8s-master-128 ~]# kubectl logs nginx-7db9fccd9b-bhldc</span><br></pre></td></tr></table></figure>
<h2 id="十、部署Web-UI（Dashboard）"><a href="#十、部署Web-UI（Dashboard）" class="headerlink" title="十、部署Web UI（Dashboard）"></a>十、部署Web UI（Dashboard）</h2><p>部署UI这部分网上有很多方法，如果下文有你看不懂的地方，可以不用参考我这里的方案</p>
<p>在kubernetes源码里有关于Dashboard的部署文件：<a href="https://github.com/kubernetes/kubernetes/tree/master/cluster/addons/dashboard" target="_blank" rel="noopener">https://github.com/kubernetes/kubernetes/tree/master/cluster/addons/dashboard</a><br><a href="https://github.com/kubernetes/dashboard" target="_blank" rel="noopener">https://github.com/kubernetes/dashboard</a></p>
<p>文件的细节这里不展开解释，需要具备一定阅读能力。</p>
<h3 id="10-1、获取YAML文件"><a href="#10-1、获取YAML文件" class="headerlink" title="10.1、获取YAML文件"></a>10.1、获取YAML文件</h3><p>从源码包获取文件<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-128 ~]# cd /root/soft/kubernetes</span><br><span class="line">[root@k8s-master-128 kubernetes]# tar zxf kubernetes-src.tar.gz</span><br><span class="line">[root@k8s-master-128 kubernetes]# ls -lh cluster/addons/dashboard/  # 在源码包里获取这些文件</span><br><span class="line">总用量 32K</span><br><span class="line">-rw-rw-r-- 1 root root 264 3月 21 13:51 dashboard-configmap.yaml</span><br><span class="line">-rw-rw-r-- 1 root root 1.8K 3月 21 13:51 dashboard-controller.yaml</span><br><span class="line">-rw-rw-r-- 1 root root 1.4K 3月 21 13:51 dashboard-rbac.yaml</span><br><span class="line">-rw-rw-r-- 1 root root 551 3月 21 13:51 dashboard-secret.yaml</span><br><span class="line">-rw-rw-r-- 1 root root 322 3月 21 13:51 dashboard-service.yaml</span><br></pre></td></tr></table></figure></p>
<h3 id="10-2、更改YAML文件"><a href="#10-2、更改YAML文件" class="headerlink" title="10.2、更改YAML文件"></a>10.2、更改YAML文件</h3><p>dashboard-controller配置文件里引用的国外镜像源，因此需要更改成国内的源才可启动<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-128 kubernetes]# cd cluster/addons/dashboard</span><br><span class="line">[root@k8s-master-128 dashboard]# vim dashboard-controller.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">    addonmanager.kubernetes.io/mode: Reconcile</span><br><span class="line">  name: kubernetes-dashboard</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: kubernetes-dashboard</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">    kubernetes.io/cluster-service: &quot;true&quot;</span><br><span class="line">    addonmanager.kubernetes.io/mode: Reconcile</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: kubernetes-dashboard</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: kubernetes-dashboard</span><br><span class="line">      annotations:</span><br><span class="line">        scheduler.alpha.kubernetes.io/critical-pod: &apos;&apos;</span><br><span class="line">        seccomp.security.alpha.kubernetes.io/pod: &apos;docker/default&apos;</span><br><span class="line">    spec:</span><br><span class="line">      priorityClassName: system-cluster-critical</span><br><span class="line">      containers:</span><br><span class="line">      - name: kubernetes-dashboard</span><br><span class="line">        image: registry.cn-hangzhou.aliyuncs.com/google_containers/kubernetes-dashboard-amd64:v1.10.1  # 将这里的官网镜像更改成国内镜像</span><br><span class="line">        resources:</span><br><span class="line">          limits:</span><br><span class="line">            cpu: 100m</span><br><span class="line">            memory: 300Mi</span><br><span class="line">          requests:</span><br><span class="line">            cpu: 50m</span><br><span class="line">            memory: 100Mi</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 8443</span><br><span class="line">          protocol: TCP</span><br><span class="line">        args:</span><br><span class="line">          # PLATFORM-SPECIFIC ARGS HERE</span><br><span class="line">          - --auto-generate-certificates</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: kubernetes-dashboard-certs</span><br><span class="line">          mountPath: /certs</span><br><span class="line">        - name: tmp-volume</span><br><span class="line">          mountPath: /tmp</span><br><span class="line">        livenessProbe:</span><br><span class="line">          httpGet:</span><br><span class="line">            scheme: HTTPS</span><br><span class="line">            path: /</span><br><span class="line">            port: 8443</span><br><span class="line">          initialDelaySeconds: 30</span><br><span class="line">          timeoutSeconds: 30</span><br><span class="line">      volumes:</span><br><span class="line">      - name: kubernetes-dashboard-certs</span><br><span class="line">        secret:</span><br><span class="line">          secretName: kubernetes-dashboard-certs</span><br><span class="line">      - name: tmp-volume</span><br><span class="line">        emptyDir: &#123;&#125;</span><br><span class="line">      serviceAccountName: kubernetes-dashboard</span><br><span class="line">      tolerations:</span><br><span class="line">      - key: &quot;CriticalAddonsOnly&quot;</span><br><span class="line">        operator: &quot;Exists&quot;</span><br></pre></td></tr></table></figure></p>
<p>dashboard-service.yaml 文件里需要新增：<code>type: NodePort</code>来对外提供服务；<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-128 dashboard]# cat dashboard-service.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: kubernetes-dashboard</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">    kubernetes.io/cluster-service: &quot;true&quot;</span><br><span class="line">    addonmanager.kubernetes.io/mode: Reconcile</span><br><span class="line">spec:</span><br><span class="line">  type: NodePort</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: kubernetes-dashboard</span><br><span class="line">  ports:</span><br><span class="line">  - port: 443</span><br><span class="line">    targetPort: 8443</span><br></pre></td></tr></table></figure></p>
<h3 id="10-3、执行部署"><a href="#10-3、执行部署" class="headerlink" title="10.3、执行部署"></a>10.3、执行部署</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-128 dashboard]# kubectl create -f dashboard-configmap.yaml</span><br><span class="line">configmap/kubernetes-dashboard-settings created</span><br><span class="line">[root@k8s-master-128 dashboard]# kubectl create -f dashboard-rbac.yaml</span><br><span class="line">role.rbac.authorization.k8s.io/kubernetes-dashboard-minimal created</span><br><span class="line">rolebinding.rbac.authorization.k8s.io/kubernetes-dashboard-minimal created</span><br><span class="line">[root@k8s-master-128 dashboard]# kubectl create -f dashboard-secret.yaml</span><br><span class="line">secret/kubernetes-dashboard-certs created</span><br><span class="line">secret/kubernetes-dashboard-key-holder created</span><br><span class="line">[root@k8s-master-128 dashboard]# kubectl create -f dashboard-controller.yaml</span><br><span class="line">serviceaccount/kubernetes-dashboard created</span><br><span class="line">deployment.apps/kubernetes-dashboard created</span><br><span class="line">[root@k8s-master-128 dashboard]# kubectl create -f dashboard-service.yaml</span><br><span class="line">service/kubernetes-dashboard created</span><br></pre></td></tr></table></figure>
<p><strong>查看部署情况</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-128 dashboard]# kubectl get pods -n kube-system # 指定命名空间查看Pod</span><br><span class="line">NAME READY STATUS RESTARTS AGE</span><br><span class="line">kubernetes-dashboard-7d5f7c58f5-mn44f 1/1 Running 0 2m44s</span><br><span class="line"></span><br><span class="line">[root@k8s-master-128 dashboard]# kubectl get svc -n kube-system</span><br><span class="line">NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE</span><br><span class="line">kubernetes-dashboard NodePort 10.0.0.47 &lt;none&gt; 443:34756/TCP 11s # 对外暴露了38276端口，这是能访问UI界面的端口</span><br><span class="line"></span><br><span class="line">[root@k8s-master-128 dashboard]# kubectl describe pods/kubernetes-dashboard-7d5f7c58f5-mn44f -n kube-system # 这个命令能查看pods创建过程信息</span><br></pre></td></tr></table></figure></p>
<h3 id="10-4、UI界面"><a href="#10-4、UI界面" class="headerlink" title="10.4、UI界面"></a>10.4、UI界面</h3><p><a href="https://Node节点IP:34756（节点IP之间，能负载均衡，所有随便访问哪个节点IP+端口" target="_blank" rel="noopener">https://Node节点IP:34756（节点IP之间，能负载均衡，所有随便访问哪个节点IP+端口</a> 都能访问到UI）<br><a href="https://172.16.194.130:34756" target="_blank" rel="noopener">https://172.16.194.130:34756</a></p>
<p>创建Service account并绑定默认cluster-admin管理员集群角色：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ kubectl create serviceaccount dashboard-admin -n kube-system</span><br><span class="line">$ kubectl create clusterrolebinding dashboard-admin --clusterrole=cluster-admin --serviceaccount=kube-system:dashboard-admin</span><br><span class="line">$ kubectl describe secrets -n kube-system $(kubectl get secrets -n kube-system |awk &apos;/dashboard-admin/&#123;print $1&#125;&apos;)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">输出：</span><br><span class="line">token: eyJhbGciOiJSUzI1NiIsImtpZCI6IiJ9.eyJpc3MiOiJrdWJlcm5ldGVzL3NlcnZpY2VhY2NvdW50Iiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9uYW1lc3BhY2UiOiJrdWJlLXN5c3RlbSIsImt1YmVybmV0ZXMuaW8vc2VydmljZWFjY291bnQvc2VjcmV0Lm5hbWUiOiJkYXNoYm9hcmQtYWRtaW4tdG9rZW4tOXA4ODciLCJrdWJlcm5ldGVzLmlvL3NlcnZpY2VhY2NvdW50L3NlcnZpY2UtYWNjb3VudC5uYW1lIjoiZGFzaGJvYXJkLWFkbWluIiwia3ViZXJuZXRlcy5pby9zZXJ2aWNlYWNjb3VudC9zZXJ2aWNlLWFjY291bnQudWlkIjoiMmRkODQyNzUtN2M2OS0xMWU5LTkzYzQtMDAwYzI5ZjRkYWE5Iiwic3ViIjoic3lzdGVtOnNlcnZpY2VhY2NvdW50Omt1YmUtc3lzdGVtOmRhc2hib2FyZC1hZG1pbiJ9.e96EQXa1YIbhRXeckNthFpqNaVw7jrQFqlQTgvVIropqCGZyw_PiM9CF3F5fWwGKZmrojo1_OV4xPNEgxkA1pA-FizwBsUo6flPeVnvkxgaSw2ME6D_z0nj8rIPwyNoDe6x2mLGZNtZi4JNDu5ehoKhZqSF60-rDsoYmlwhY8WVq6uuNVSu086i25q3UU8Wz963TyRZgiywP5fTIbCfikBA5Aj7Mjar9IcCsrPGKeWOm0CxaF_IFPidMWR0scNOZfwdTHC2gU6MUxwMjAQ3KRcC1j7sNQnjXd_mPuJg96SDJsWT8T9IKaMXfXa0etb_b9F5FEZ3qAdFFsKjh-pbJ7g</span><br></pre></td></tr></table></figure></p>
<p>将这个token放入Dashboard认证，即可登录到UI页面。</p>
<h2 id="十一、部署多Master节点集群"><a href="#十一、部署多Master节点集群" class="headerlink" title="十一、部署多Master节点集群"></a>十一、部署多Master节点集群</h2><p>环境规划中，选定172.16.194.127来作为另一个Master节点，主要是实现kube-apiserver的负载均衡，首先对Master节点进行部署，然后使用nginx来进行对kube-apiserver进行负载代理，实现apiserver的高可用；</p>
<h3 id="11-1、部署Master组件"><a href="#11-1、部署Master组件" class="headerlink" title="11.1、部署Master组件"></a>11.1、部署Master组件</h3><p>在172.16.194.128服务器上已经部署好了一台Master所需要的组件，这里可以直接将配置文件和启动服务文件直接拉过来即可使用</p>
<h4 id="11-1-1、拷贝文件"><a href="#11-1-1、拷贝文件" class="headerlink" title="11.1.1、拷贝文件"></a>11.1.1、拷贝文件</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"># 配置免密要环境</span><br><span class="line">[root@k8s-master-128 ~]# ssh-copy-id k8s-master-127  </span><br><span class="line"># kube-apiserver需要用到etcd的证书，因此我们将128上etcd所有文件拷贝到127</span><br><span class="line">[root@k8s-master-128 ~]# ssh k8s-master-127 mkdir -p /opt/etcd/&#123;bin,cfg,ssl&#125;</span><br><span class="line">[root@k8s-master-128 ~]# scp -r /opt/etcd/&#123;bin,cfg,ssl&#125; k8s-master-127:/opt/etcd/</span><br><span class="line"># 拷贝k8s配置文件</span><br><span class="line">[root@k8s-master-128 ~]# ssh k8s-master-127 mkdir -p /opt/kubernetes/&#123;bin,cfg,logs,ssl&#125;</span><br><span class="line">[root@k8s-master-128 ~]# scp -r /opt/kubernetes/&#123;bin,cfg,ssl&#125; k8s-master-127:/opt/kubernetes/</span><br><span class="line">[root@k8s-master-128 ~]# scp -r /usr/lib/systemd/system/kube-&#123;apiserver,controller-manager,scheduler&#125;.service k8s-master-127:/usr/lib/systemd/system/</span><br><span class="line"></span><br><span class="line"># 更改配置信息</span><br><span class="line">[root@k8s-master-127 ~]# cd /opt/kubernetes/cfg/</span><br><span class="line">[root@k8s-master-127 cfg]# vim kube-apiserver</span><br><span class="line"># 将以下参数的IP值更改为对应主机IP，其他的不变</span><br><span class="line">--bind-address=172.16.194.127</span><br><span class="line">--advertise-address=172.16.194.127</span><br><span class="line"></span><br><span class="line"># kube-controller-manager与kube-schedule组件的配置不用更改，并且这两个组件都有负载均衡功能：</span><br><span class="line">--leader-elect</span><br></pre></td></tr></table></figure>
<h4 id="11-1-2、启动组件"><a href="#11-1-2、启动组件" class="headerlink" title="11.1.2、启动组件"></a>11.1.2、启动组件</h4><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-127 ~]# systemctl start kube-apiserver</span><br><span class="line">[root@k8s-master-127 ~]# systemctl start kube-controller-manager</span><br><span class="line">[root@k8s-master-127 ~]# systemctl start kube-scheduler</span><br><span class="line">[root@k8s-master-127 ~]# systemctl enable kube-apiserver</span><br><span class="line">[root@k8s-master-127 ~]# systemctl enable kube-controller-manager</span><br><span class="line">[root@k8s-master-127 ~]# systemctl enable kube-scheduler</span><br><span class="line"></span><br><span class="line">[root@k8s-master-127 ~]# netstat -lntup|grep kube</span><br><span class="line">tcp 0 0 172.16.194.127:6443 0.0.0.0:* LISTEN 7344/kube-apiserver</span><br><span class="line">tcp 0 0 127.0.0.1:10252 0.0.0.0:* LISTEN 7362/kube-controlle</span><br><span class="line">tcp 0 0 127.0.0.1:8080 0.0.0.0:* LISTEN 7344/kube-apiserver</span><br><span class="line">tcp6 0 0 :::10251 :::* LISTEN 7375/kube-scheduler</span><br><span class="line">tcp6 0 0 :::10257 :::* LISTEN 7362/kube-controlle</span><br><span class="line">tcp6 0 0 :::10259 :::* LISTEN 7375/kube-scheduler</span><br></pre></td></tr></table></figure>
<p>启动完成。<br>配置环境变量和查看集群状态：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-127 ~]# echo &quot;export PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin:/opt/kubernetes/bin&quot; &gt;&gt;/etc/profile</span><br><span class="line">[root@k8s-master-127 ~]# source /etc/profile</span><br><span class="line">[root@k8s-master-127 ~]# which kubectl</span><br><span class="line">/opt/kubernetes/bin/kubectl</span><br><span class="line"></span><br><span class="line">[root@k8s-master-127 ~]# kubectl get pods</span><br><span class="line">NAME READY STATUS RESTARTS AGE</span><br><span class="line">nginx-7db9fccd9b-bhldc 1/1 Running 0 4d7h</span><br><span class="line">[root@k8s-master-127 ~]# kubectl get pods -n kube-system</span><br><span class="line">NAME READY STATUS RESTARTS AGE</span><br><span class="line">kubernetes-dashboard-7d5f7c58f5-dvz5m 1/1 Running 5 3d13h</span><br><span class="line">[root@k8s-master-127 ~]# kubectl get svc</span><br><span class="line">NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE</span><br><span class="line">kubernetes ClusterIP 10.0.0.1 &lt;none&gt; 443/TCP 5d6h</span><br><span class="line">nginx NodePort 10.0.0.86 &lt;none&gt; 80:43364/TCP 4d7h</span><br><span class="line">[root@k8s-master-127 ~]# kubectl get svc -n kube-system</span><br><span class="line">NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE</span><br><span class="line">kubernetes-dashboard NodePort 10.0.0.47 &lt;none&gt; 443:34756/TCP 4d6h</span><br><span class="line">[root@k8s-master-127 ~]# kubectl get cs</span><br><span class="line">NAME STATUS MESSAGE ERROR</span><br><span class="line">scheduler Healthy ok</span><br><span class="line">controller-manager Healthy ok</span><br><span class="line">etcd-1 Healthy &#123;&quot;health&quot;:&quot;true&quot;&#125;</span><br><span class="line">etcd-0 Healthy &#123;&quot;health&quot;:&quot;true&quot;&#125;</span><br><span class="line">etcd-2 Healthy &#123;&quot;health&quot;:&quot;true&quot;&#125;</span><br></pre></td></tr></table></figure></p>
<p>能看到127节点可以正常接入集群并使用。</p>
<h3 id="11-2、Nginx负载Master节点"><a href="#11-2、Nginx负载Master节点" class="headerlink" title="11.2、Nginx负载Master节点"></a>11.2、Nginx负载Master节点</h3><p>官网安装文档：<a href="http://nginx.org/en/linux_packages.html" target="_blank" rel="noopener">http://nginx.org/en/linux_packages.html</a></p>
<p>选择自己的OS环境并进行nginx安装，因为实验环境机器有限，这里使用127和128两台k8s的Master节点来安装Nginx来进行实验。与前期环境规划一致。</p>
<p>安装：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-127 ~]# vim /etc/yum.repos.d/nginx.repo</span><br><span class="line">[nginx-stable]</span><br><span class="line">name=nginx stable repo</span><br><span class="line">baseurl=http://nginx.org/packages/centos/$releasever/$basearch/</span><br><span class="line">gpgcheck=1</span><br><span class="line">enabled=1</span><br><span class="line">gpgkey=https://nginx.org/keys/nginx_signing.key</span><br><span class="line"></span><br><span class="line">[root@k8s-master-127 ~]# yum install nginx -y</span><br></pre></td></tr></table></figure></p>
<p>启动nginx：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-127 ~]#  systemctl start nginx</span><br><span class="line">[root@k8s-master-127 ~]# systemctl enable nginx</span><br></pre></td></tr></table></figure></p>
<p>配置：<br>nginx配置目录在/etc/nginx/下，主配置文件nginx.conf，生产环境需要对这个配置文件进行调优，而这里做实验的话默认配置就行。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-127 nginx]# cat nginx.conf</span><br><span class="line">···略···</span><br><span class="line">events &#123;</span><br><span class="line">    worker_connections 1024;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"># stream模块用于代理4层请求，且不能存在http模块内</span><br><span class="line">stream &#123;</span><br><span class="line">    log_format main &apos;$remote_addr $upstream_addr $time_local $status&apos;;</span><br><span class="line">    access_log /var/log/nginx/k8s-apiserver.com.access_log main;</span><br><span class="line">    error_log /var/log/nginx/k8s-apiserver.com.error_log warn;</span><br><span class="line">    upstream k8s-apiserver &#123;</span><br><span class="line">         server 172.16.194.127:6443;</span><br><span class="line">         server 172.16.194.128:6443;</span><br><span class="line">    &#125;</span><br><span class="line">    server &#123;</span><br><span class="line">          listen 172.16.194.127:6444;</span><br><span class="line">          proxy_pass k8s-apiserver;  # 代理4层请求，不用加http://</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">http &#123;</span><br><span class="line">···略···</span><br><span class="line">&#125;</span><br><span class="line">···略···</span><br></pre></td></tr></table></figure>
<p>查看启动：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-127 nginx]# netstat -lntup|grep 6444</span><br><span class="line">tcp 0 0 172.16.194.127:6444 0.0.0.0:* LISTEN 7061/nginx: master</span><br></pre></td></tr></table></figure></p>
<p>因为本机有6443，想要与代理理共存的话，nginx更改下端口即可。</p>
<h3 id="11-3、Node节点配置使用"><a href="#11-3、Node节点配置使用" class="headerlink" title="11.3、Node节点配置使用"></a>11.3、Node节点配置使用</h3><p>更改Node节点的配置：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-node-129 ~]# cd /opt/kubernetes/cfg/</span><br><span class="line">[root@k8s-node-129 cfg]# grep &quot;6443&quot; ./*  # 将这三个文件的地址更改为api-server的代理地址</span><br><span class="line">./bootstrap.kubeconfig: server: https://172.16.194.128:6443</span><br><span class="line">./kubelet.kubeconfig: server: https://172.16.194.128:6443</span><br><span class="line">./kube-proxy.kubeconfig: server: https://172.16.194.128:6443</span><br><span class="line"></span><br><span class="line"># 更改后：(所有节点都需要更改)</span><br><span class="line">[root@k8s-node-129 cfg]# grep &quot;6444&quot; ./*</span><br><span class="line">./bootstrap.kubeconfig: server: https://172.16.194.127:6444</span><br><span class="line">./kubelet.kubeconfig: server: https://172.16.194.127:6444</span><br><span class="line">./kube-proxy.kubeconfig: server: https://172.16.194.127:6444</span><br></pre></td></tr></table></figure></p>
<p>重启Node节点组件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-node-129 cfg]# systemctl restart kubelet</span><br><span class="line">[root@k8s-node-129 cfg]# systemctl restart kube-proxy</span><br></pre></td></tr></table></figure></p>
<p>查看nginx代理日志：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-127 nginx]# tail -f k8s-apiserver.com.access_log</span><br><span class="line">172.16.194.130 172.16.194.127:6443 13/May/2019:03:12:07 +0800 200</span><br><span class="line">172.16.194.130 172.16.194.127:6443 13/May/2019:03:12:07 +0800 200</span><br><span class="line">172.16.194.130 172.16.194.128:6443 13/May/2019:03:12:13 +0800 200</span><br><span class="line">172.16.194.130 172.16.194.128:6443 13/May/2019:03:12:13 +0800 200</span><br><span class="line">172.16.194.130 172.16.194.128:6443 13/May/2019:03:12:13 +0800 200</span><br></pre></td></tr></table></figure></p>
<p>代理成功。</p>
<p>查看集群Node节点状态：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-127 nginx]# kubectl get node</span><br><span class="line">NAME STATUS ROLES AGE VERSION</span><br><span class="line">172.16.194.129 Ready &lt;none&gt; 5d10h v1.14.0</span><br><span class="line">172.16.194.130 Ready &lt;none&gt; 5d10h v1.14.0</span><br></pre></td></tr></table></figure></p>
<p>只有代理连接是正常的，集群节点才会是Ready状态，否则就是上面配置环境有问题。</p>
<h3 id="11-4、Keepalived实现Nginx高可用"><a href="#11-4、Keepalived实现Nginx高可用" class="headerlink" title="11.4、Keepalived实现Nginx高可用"></a>11.4、Keepalived实现Nginx高可用</h3><p>目前只部署了一个Nginx节点，只有一个节点就存在单点故障的风险，一旦这个节点挂掉，那么整个集群将会不可用，<br>市场有些可选的高可用开源解决方案，如：Keepalived、heartbeat等，这里我们选择使用前者。</p>
<p>大致的思路就是：<br>1、将上面的Nginx代理节点配置多个（两个以上）；<br>2、通过Keepalived控制VIP来进行漂移，如果Nginx代理节点挂掉后，Keepalived会将VIP漂移到正常的Nginx代理节点上，从而实现集群高可用，提高k8s集群的健壮性。</p>
<p>127节点已经安装和配置好Nginx，128节点按照上面的配置即可。</p>
<h4 id="11-4-1、Keepalived安装与配置"><a href="#11-4-1、Keepalived安装与配置" class="headerlink" title="11.4.1、Keepalived安装与配置"></a>11.4.1、Keepalived安装与配置</h4><p>127Master节点部署：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-127 ~]# yum install keepalived -y</span><br><span class="line">[root@k8s-master-127 ~]# vim /etc/keepalived/keepalived.conf</span><br><span class="line">! Configuration File for keepalived</span><br><span class="line"></span><br><span class="line">global_defs &#123;</span><br><span class="line">   notification_email &#123;</span><br><span class="line">     acassen@firewall.loc</span><br><span class="line">     failover@firewall.loc</span><br><span class="line">     sysadmin@firewall.loc</span><br><span class="line">   &#125;</span><br><span class="line">   notification_email_from Alexandre.Cassen@firewall.loc</span><br><span class="line">   smtp_server 127.0.0.1</span><br><span class="line">   smtp_connect_timeout 30</span><br><span class="line">   router_id NGINX_MASTER</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_script check_nginx &#123;</span><br><span class="line">    script &quot;/etc/keepalived/check_nginx.sh&quot;</span><br><span class="line">    interval 2</span><br><span class="line">    weight 2</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state MASTER</span><br><span class="line">    interface eth0</span><br><span class="line">    virtual_router_id 50</span><br><span class="line">    priority 100</span><br><span class="line">    advert_int 1</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass 1111</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        172.16.194.111</span><br><span class="line">    &#125;</span><br><span class="line">    track_script &#123;</span><br><span class="line">        check_nginx</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>检查nginx的脚本：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-127 ~]# cat /etc/keepalived/check_nginx.sh</span><br><span class="line">count=$(ps -C nginx --no-header |wc -l)</span><br><span class="line"></span><br><span class="line">if [ $count -eq 0 ];then</span><br><span class="line">    systemctl stop keepalived</span><br><span class="line">fi</span><br><span class="line">[root@k8s-master-127 ~]# chmod +x /etc/keepalived/check_nginx.sh</span><br></pre></td></tr></table></figure></p>
<p>启动主节点的Keepalived：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-127 ~]# systemctl enable keepalived</span><br><span class="line">[root@k8s-master-127 ~]# systemctl start keepalived</span><br></pre></td></tr></table></figure></p>
<p><code>注意：Keepalived不可设置成开机自启动，一旦发生VIP漂移，则需要运维工程师介入排查问题，如果设置成开启启动，有可能会给业务带来二次伤害。</code></p>
<p>查看Keepalived绑定的VIP：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-127 ~]# ip a</span><br><span class="line">···略···</span><br><span class="line">2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000</span><br><span class="line">    link/ether 00:0c:29:41:09:16 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 172.16.194.127/24 brd 172.16.194.255 scope global noprefixroute eth0   # 这是本机IP</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet 172.16.194.111/32 scope global eth0  # 这是VIP</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">···略···</span><br></pre></td></tr></table></figure></p>
<p>128Backup节点部署：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-128 nginx]# yum install keepalived -y</span><br><span class="line">[root@k8s-master-128 nginx]# vim /etc/keepalived/keepalived.conf</span><br><span class="line">! Configuration File for keepalived</span><br><span class="line"></span><br><span class="line">global_defs &#123;</span><br><span class="line">   notification_email &#123;</span><br><span class="line">     acassen@firewall.loc</span><br><span class="line">     failover@firewall.loc</span><br><span class="line">     sysadmin@firewall.loc</span><br><span class="line">   &#125;</span><br><span class="line">   notification_email_from Alexandre.Cassen@firewall.loc</span><br><span class="line">   smtp_server 127.0.0.1</span><br><span class="line">   smtp_connect_timeout 30</span><br><span class="line">   router_id NGINX_BACKUP</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_script check_nginx &#123;</span><br><span class="line">    script &quot;/etc/keepalived/check_nginx.sh&quot;</span><br><span class="line">    interval 2</span><br><span class="line">    weight 2</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">vrrp_instance VI_1 &#123;</span><br><span class="line">    state BACKUP</span><br><span class="line">    interface eth0</span><br><span class="line">    virtual_router_id 50  # 这个参数要与Master一样，不然不能识别及通讯</span><br><span class="line">    priority 50</span><br><span class="line">    advert_int 1</span><br><span class="line">    authentication &#123;</span><br><span class="line">        auth_type PASS</span><br><span class="line">        auth_pass 1111</span><br><span class="line">    &#125;</span><br><span class="line">    virtual_ipaddress &#123;</span><br><span class="line">        172.16.194.111/24</span><br><span class="line">    &#125;</span><br><span class="line">    track_script &#123;</span><br><span class="line">        check_nginx</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>检查nginx的脚本：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-128 nginx]# vim /etc/keepalived/check_nginx.sh</span><br><span class="line">count=$(ps -C nginx --no-header |wc -l)</span><br><span class="line"></span><br><span class="line">if [ $count -eq 0 ];then</span><br><span class="line">    systemctl stop keepalived</span><br><span class="line">fi</span><br><span class="line">[root@k8s-master-128 nginx]# chmod +x /etc/keepalived/check_nginx.sh</span><br></pre></td></tr></table></figure></p>
<p>启动备节点的Keepalived：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-128 nginx]# systemctl enable keepalived</span><br><span class="line">[root@k8s-master-128 nginx]# systemctl start keepalived</span><br></pre></td></tr></table></figure></p>
<h4 id="11-4-2、故障模拟测试"><a href="#11-4-2、故障模拟测试" class="headerlink" title="11.4.2、故障模拟测试"></a>11.4.2、故障模拟测试</h4><p>现在状态：127Master节点和128Backup节点都已经启动，VIP绑定在127的eth0网卡上；<br>理论上，将nginx停掉，VIP会从当前节点消失，漂移到备节点上，那来看实际情况：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"># 模拟故障停掉nginx，看看VIP是否会漂移到备用节点上</span><br><span class="line">[root@k8s-master-127 ~]# systemctl stop nginx</span><br><span class="line">[root@k8s-master-127 ~]# ip a</span><br><span class="line">···略···</span><br><span class="line">2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000</span><br><span class="line">    link/ether 00:0c:29:41:09:16 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 172.16.194.127/24 brd 172.16.194.255 scope global noprefixroute eth0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">···略···</span><br><span class="line"></span><br><span class="line"># 查看备节点是否有VIP</span><br><span class="line">[root@k8s-master-128 ~]# ip a</span><br><span class="line">···略···</span><br><span class="line">2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP group default qlen 1000</span><br><span class="line">    link/ether 00:0c:29:f4:da:a9 brd ff:ff:ff:ff:ff:ff</span><br><span class="line">    inet 172.16.194.128/24 brd 172.16.194.255 scope global noprefixroute eth0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">    inet 172.16.194.111/24 scope global secondary eth0</span><br><span class="line">       valid_lft forever preferred_lft forever</span><br><span class="line">···略···</span><br></pre></td></tr></table></figure></p>
<p>跟理论情况一样，因故障后，VIP漂移正常，那也就意味着负载均衡加高可用集群搭建完成。</p>
<h3 id="11-5、k8s集群接入负载均衡使用"><a href="#11-5、k8s集群接入负载均衡使用" class="headerlink" title="11.5、k8s集群接入负载均衡使用"></a>11.5、k8s集群接入负载均衡使用</h3><p>kube-apiserver的负载均衡主备节点都已经搭建完成并测试成功，接下来就需要配置下k8s的Node组件使用即可</p>
<h4 id="11-5-1、更改Nginx配置"><a href="#11-5-1、更改Nginx配置" class="headerlink" title="11.5.1、更改Nginx配置"></a>11.5.1、更改Nginx配置</h4><p>127和128节点的nginx更改如下<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-127 ~]# vim /etc/nginx/nginx.conf</span><br><span class="line">stream &#123;</span><br><span class="line">    log_format main &apos;$remote_addr $upstream_addr $time_local $status&apos;;</span><br><span class="line">    access_log /var/log/nginx/k8s-apiserver.com.access_log main;</span><br><span class="line">    error_log /var/log/nginx/k8s-apiserver.com.error_log warn;</span><br><span class="line">    upstream k8s-apiserver &#123;</span><br><span class="line">        server 172.16.194.127:6443;</span><br><span class="line">        server 172.16.194.128:6443;</span><br><span class="line">    &#125;</span><br><span class="line">    server &#123;</span><br><span class="line">        listen 0.0.0.0:6444;  # 将这里更改为监听所有网段</span><br><span class="line">        proxy_pass k8s-apiserver;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<p>重新加载nginx，使配置生效：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-127 ~]# systemctl reload nginx</span><br><span class="line">[root@k8s-master-127 ~]# netstat -lntup|grep nginx</span><br><span class="line">tcp 0 0 0.0.0.0:6444 0.0.0.0:* LISTEN 20523/nginx: master</span><br><span class="line"></span><br><span class="line">[root@k8s-master-128 ~]# systemctl reload nginx</span><br><span class="line">[root@k8s-master-128 ~]# netstat -lntup|grep nginx</span><br><span class="line">tcp 0 0 0.0.0.0:6444 0.0.0.0:* LISTEN 21604/nginx: master</span><br></pre></td></tr></table></figure></p>
<h4 id="11-5-2、Node节点配置使用"><a href="#11-5-2、Node节点配置使用" class="headerlink" title="11.5.2、Node节点配置使用"></a>11.5.2、Node节点配置使用</h4><p>更改api-server地址的配置<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-node-129 cfg]# grep &apos;111&apos; ./*</span><br><span class="line">./bootstrap.kubeconfig: server: https://172.16.194.111:6444</span><br><span class="line">./kubelet.kubeconfig: server: https://172.16.194.111:6444</span><br><span class="line">./kube-proxy.kubeconfig: server: https://172.16.194.111:6444</span><br><span class="line"></span><br><span class="line">[root@k8s-node-130 cfg]# grep &apos;111&apos; ./*</span><br><span class="line">./bootstrap.kubeconfig: server: https://172.16.194.111:6444</span><br><span class="line">./kubelet.kubeconfig: server: https://172.16.194.111:6444</span><br><span class="line">./kube-proxy.kubeconfig: server: https://172.16.194.111:6444</span><br></pre></td></tr></table></figure></p>
<p>重启kubelet和kube-proxy组件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-node-129 cfg]# systemctl restart kubelet</span><br><span class="line">[root@k8s-node-129 cfg]# systemctl restart kube-proxy</span><br><span class="line">[root@k8s-node-130 cfg]# systemctl restart kubelet</span><br><span class="line">[root@k8s-node-130 cfg]# systemctl restart kube-proxy</span><br></pre></td></tr></table></figure></p>
<p>查看127上的代理日志：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-127 ~]# tail -f /var/log/nginx/k8s-apiserver.com.access_log</span><br><span class="line">172.16.194.130 172.16.194.127:6443 13/May/2019:05:32:55 +0800 200</span><br><span class="line">172.16.194.129 172.16.194.128:6443 13/May/2019:05:32:55 +0800 200</span><br><span class="line">172.16.194.129 172.16.194.127:6443 13/May/2019:05:32:55 +0800 200</span><br><span class="line">172.16.194.130 172.16.194.128:6443 13/May/2019:05:32:55 +0800 200</span><br></pre></td></tr></table></figure></p>
<p>nginx默认是轮训代理。</p>
<h4 id="11-5-3、K8集群状态"><a href="#11-5-3、K8集群状态" class="headerlink" title="11.5.3、K8集群状态"></a>11.5.3、K8集群状态</h4><p>能看到Node节点状态是Ready就没事<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-128 ~]# kubectl get nodes</span><br><span class="line">NAME STATUS ROLES AGE VERSION</span><br><span class="line">172.16.194.129 Ready &lt;none&gt; 7d v1.14.0</span><br><span class="line">172.16.194.130 Ready &lt;none&gt; 7d v1.14.0</span><br></pre></td></tr></table></figure></p>
<p>遇到的坑：<br>1、在生成server证书的时候，需要将VIP填写进去并生成证书，不然就会报错如下：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 启动kubelet查看/var/log/messages</span><br><span class="line">certificate is valid for 127.0.0.1, 10.0.0.1, 172.16.194.127, 172.16.194.128, 172.16.194.129, 172.16.194.130, not 172.16.194.111</span><br></pre></td></tr></table></figure></p>
<p>解决办法：将server证书重新生成（填写VIP进去），并重启api-server进程即可解决。</p>
<h2 id="十二、部署集群内部DNS解析服务（CoreDNS）"><a href="#十二、部署集群内部DNS解析服务（CoreDNS）" class="headerlink" title="十二、部署集群内部DNS解析服务（CoreDNS）"></a>十二、部署集群内部DNS解析服务（CoreDNS）</h2><p>在kubernetes1.12之后的版本中，使用了CoreDNS作为默认的DNS；<br>官网：<a href="https://github.com/kubernetes/kubernetes/blob/master/cluster/addons/dns/coredns/" target="_blank" rel="noopener">https://github.com/kubernetes/kubernetes/blob/master/cluster/addons/dns/coredns/</a></p>
<h3 id="12-1、下载CoreDNS部署文件"><a href="#12-1、下载CoreDNS部署文件" class="headerlink" title="12.1、下载CoreDNS部署文件"></a>12.1、下载CoreDNS部署文件</h3><p><a href="https://github.com/coredns/deployment/tree/master/kubernetes" target="_blank" rel="noopener">https://github.com/coredns/deployment/tree/master/kubernetes</a><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-128 ~]# mkdir coredns &amp;&amp; cd coredns</span><br><span class="line">[root@k8s-master-128 coredns]# wget https://raw.githubusercontent.com/coredns/deployment/master/kubernetes/coredns.yaml.sed</span><br><span class="line">[root@k8s-master-128 coredns]# wget https://raw.githubusercontent.com/coredns/deployment/master/kubernetes/deploy.sh</span><br></pre></td></tr></table></figure></p>
<p>deploy.sh是一个便捷的脚本，用于生成用于在当前运行标准kube-dns的集群上运行CoreDNS的清单。使用coredns.yaml.sed文件作为模板，它创建一个ConfigMap和一个CoreDNS deployment，然后更新 Kube-DNS service selector以使用CoreDNS deployment。 通过重新使用现有服务，服务请求不会中断。</p>
<h3 id="12-2、部署CoreDNS"><a href="#12-2、部署CoreDNS" class="headerlink" title="12.2、部署CoreDNS"></a>12.2、部署CoreDNS</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-128 coredns]# chmod +x deploy.sh</span><br><span class="line">[root@k8s-master-128 coredns]# ./deploy.sh -i 10.0.0.2 &gt;coredns.yaml</span><br><span class="line">     tips: </span><br><span class="line">       少了个jq命令：yum install -y jq</span><br><span class="line"></span><br><span class="line">[root@k8s-master-128 coredns]# kubectl create -f coredns.yaml</span><br><span class="line">serviceaccount/coredns created</span><br><span class="line">clusterrole.rbac.authorization.k8s.io/system:coredns created</span><br><span class="line">clusterrolebinding.rbac.authorization.k8s.io/system:coredns created</span><br><span class="line">configmap/coredns created</span><br><span class="line">deployment.apps/coredns created</span><br><span class="line">service/kube-dns created</span><br></pre></td></tr></table></figure>
<p>查看生成的文件：<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ServiceAccount</span><br><span class="line">metadata:</span><br><span class="line">  name: coredns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRole</span><br><span class="line">metadata:</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io/bootstrapping: rbac-defaults</span><br><span class="line">  name: system:coredns</span><br><span class="line">rules:</span><br><span class="line">- apiGroups:</span><br><span class="line">  - &quot;&quot;</span><br><span class="line">  resources:</span><br><span class="line">  - endpoints</span><br><span class="line">  - services</span><br><span class="line">  - pods</span><br><span class="line">  - namespaces</span><br><span class="line">  verbs:</span><br><span class="line">  - list</span><br><span class="line">  - watch</span><br><span class="line">- apiGroups:</span><br><span class="line">  - &quot;&quot;</span><br><span class="line">  resources:</span><br><span class="line">  - nodes</span><br><span class="line">  verbs:</span><br><span class="line">  - get</span><br><span class="line">---</span><br><span class="line">apiVersion: rbac.authorization.k8s.io/v1</span><br><span class="line">kind: ClusterRoleBinding</span><br><span class="line">metadata:</span><br><span class="line">  annotations:</span><br><span class="line">    rbac.authorization.kubernetes.io/autoupdate: &quot;true&quot;</span><br><span class="line">  labels:</span><br><span class="line">    kubernetes.io/bootstrapping: rbac-defaults</span><br><span class="line">  name: system:coredns</span><br><span class="line">roleRef:</span><br><span class="line">  apiGroup: rbac.authorization.k8s.io</span><br><span class="line">  kind: ClusterRole</span><br><span class="line">  name: system:coredns</span><br><span class="line">subjects:</span><br><span class="line">- kind: ServiceAccount</span><br><span class="line">  name: coredns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: ConfigMap</span><br><span class="line">metadata:</span><br><span class="line">  name: coredns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">data:</span><br><span class="line">  Corefile: |</span><br><span class="line">    .:53 &#123;</span><br><span class="line">        errors</span><br><span class="line">        health</span><br><span class="line">        ready</span><br><span class="line">        kubernetes cluster.local in-addr.arpa ip6.arpa &#123;</span><br><span class="line">          pods insecure</span><br><span class="line">          fallthrough in-addr.arpa ip6.arpa</span><br><span class="line">        &#125;</span><br><span class="line">        prometheus :9153</span><br><span class="line">        forward . /etc/resolv.conf</span><br><span class="line">        cache 30</span><br><span class="line">        loop</span><br><span class="line">        reload</span><br><span class="line">        loadbalance</span><br><span class="line">    &#125;</span><br><span class="line">---</span><br><span class="line">apiVersion: apps/v1</span><br><span class="line">kind: Deployment</span><br><span class="line">metadata:</span><br><span class="line">  name: coredns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kube-dns</span><br><span class="line">    kubernetes.io/name: &quot;CoreDNS&quot;</span><br><span class="line">spec:</span><br><span class="line">  replicas: 2</span><br><span class="line">  strategy:</span><br><span class="line">    type: RollingUpdate</span><br><span class="line">    rollingUpdate:</span><br><span class="line">      maxUnavailable: 1</span><br><span class="line">  selector:</span><br><span class="line">    matchLabels:</span><br><span class="line">      k8s-app: kube-dns</span><br><span class="line">  template:</span><br><span class="line">    metadata:</span><br><span class="line">      labels:</span><br><span class="line">        k8s-app: kube-dns</span><br><span class="line">    spec:</span><br><span class="line">      priorityClassName: system-cluster-critical</span><br><span class="line">      serviceAccountName: coredns</span><br><span class="line">      tolerations:</span><br><span class="line">        - key: &quot;CriticalAddonsOnly&quot;</span><br><span class="line">          operator: &quot;Exists&quot;</span><br><span class="line">      nodeSelector:</span><br><span class="line">        beta.kubernetes.io/os: linux</span><br><span class="line">      containers:</span><br><span class="line">      - name: coredns</span><br><span class="line">        image: coredns/coredns:1.5.0</span><br><span class="line">        imagePullPolicy: IfNotPresent</span><br><span class="line">        resources:</span><br><span class="line">          limits:</span><br><span class="line">            memory: 170Mi</span><br><span class="line">          requests:</span><br><span class="line">            cpu: 100m</span><br><span class="line">            memory: 70Mi</span><br><span class="line">        args: [ &quot;-conf&quot;, &quot;/etc/coredns/Corefile&quot; ]</span><br><span class="line">        volumeMounts:</span><br><span class="line">        - name: config-volume</span><br><span class="line">          mountPath: /etc/coredns</span><br><span class="line">          readOnly: true</span><br><span class="line">        ports:</span><br><span class="line">        - containerPort: 53</span><br><span class="line">          name: dns</span><br><span class="line">          protocol: UDP</span><br><span class="line">        - containerPort: 53</span><br><span class="line">          name: dns-tcp</span><br><span class="line">          protocol: TCP</span><br><span class="line">        - containerPort: 9153</span><br><span class="line">          name: metrics</span><br><span class="line">          protocol: TCP</span><br><span class="line">        securityContext:</span><br><span class="line">          allowPrivilegeEscalation: false</span><br><span class="line">          capabilities:</span><br><span class="line">            add:</span><br><span class="line">            - NET_BIND_SERVICE</span><br><span class="line">            drop:</span><br><span class="line">            - all</span><br><span class="line">          readOnlyRootFilesystem: true</span><br><span class="line">        livenessProbe:</span><br><span class="line">          httpGet:</span><br><span class="line">            path: /health</span><br><span class="line">            port: 8080</span><br><span class="line">            scheme: HTTP</span><br><span class="line">          initialDelaySeconds: 60</span><br><span class="line">          timeoutSeconds: 5</span><br><span class="line">          successThreshold: 1</span><br><span class="line">          failureThreshold: 5</span><br><span class="line">        readinessProbe:</span><br><span class="line">          httpGet:</span><br><span class="line">            path: /ready</span><br><span class="line">            port: 8181</span><br><span class="line">            scheme: HTTP</span><br><span class="line">      dnsPolicy: Default</span><br><span class="line">      volumes:</span><br><span class="line">        - name: config-volume</span><br><span class="line">          configMap:</span><br><span class="line">            name: coredns</span><br><span class="line">            items:</span><br><span class="line">            - key: Corefile</span><br><span class="line">              path: Corefile</span><br><span class="line">---</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Service</span><br><span class="line">metadata:</span><br><span class="line">  name: kube-dns</span><br><span class="line">  namespace: kube-system</span><br><span class="line">  annotations:</span><br><span class="line">    prometheus.io/port: &quot;9153&quot;</span><br><span class="line">    prometheus.io/scrape: &quot;true&quot;</span><br><span class="line">  labels:</span><br><span class="line">    k8s-app: kube-dns</span><br><span class="line">    kubernetes.io/cluster-service: &quot;true&quot;</span><br><span class="line">    kubernetes.io/name: &quot;CoreDNS&quot;</span><br><span class="line">spec:</span><br><span class="line">  selector:</span><br><span class="line">    k8s-app: kube-dns</span><br><span class="line">  clusterIP: 10.0.0.2</span><br><span class="line">  ports:</span><br><span class="line">  - name: dns</span><br><span class="line">    port: 53</span><br><span class="line">    protocol: UDP</span><br><span class="line">  - name: dns-tcp</span><br><span class="line">    port: 53</span><br><span class="line">    protocol: TCP</span><br><span class="line">  - name: metrics</span><br><span class="line">    port: 9153</span><br><span class="line">    protocol: TCP</span><br></pre></td></tr></table></figure></p>
<p>早在部署kubelet的时候就通过<code>--cluster-dns=10.0.0.2 --cluster-domain=cluster.local</code>参数指定了dns地址和解析的域，因此直接部署即可使用，如果kubelet启动参数里没有配置这两个dns参数的话，上面部署coredns之后还需要将所有kubelet重新添加配置并重启进程。</p>
<h3 id="12-3、查看CoreDNS状态"><a href="#12-3、查看CoreDNS状态" class="headerlink" title="12.3、查看CoreDNS状态"></a>12.3、查看CoreDNS状态</h3><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-128 coredns]# kubectl get pods -n kube-system</span><br><span class="line">NAME READY STATUS RESTARTS AGE</span><br><span class="line">coredns-55f46dd959-q47j5 1/1 Running 0 3m59s</span><br><span class="line">coredns-55f46dd959-vcj4w 1/1 Running 0 3m59s</span><br><span class="line">kubernetes-dashboard-7d5f7c58f5-xqvmh 1/1 Running 1 94m</span><br><span class="line"></span><br><span class="line">[root@k8s-master-128 coredns]# kubectl get svc -n kube-system</span><br><span class="line">NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE</span><br><span class="line">kube-dns ClusterIP 10.0.0.2 &lt;none&gt; 53/UDP,53/TCP,9153/TCP 4m12s</span><br><span class="line">kubernetes-dashboard NodePort 10.0.0.47 &lt;none&gt; 443:34756/TCP 14d</span><br><span class="line"></span><br><span class="line">[root@k8s-master-128 coredns]# kubectl get deploy -n kube-system</span><br><span class="line">NAME READY UP-TO-DATE AVAILABLE AGE</span><br><span class="line">coredns 2/2 2 2 5m32s</span><br><span class="line">kubernetes-dashboard 1/1 1 1 14d</span><br><span class="line"></span><br><span class="line">[root@k8s-master-128 coredns]# kubectl get ep -n kube-system kube-dns</span><br><span class="line">NAME ENDPOINTS AGE</span><br><span class="line">kube-dns 172.17.17.4:53,172.17.50.2:53,172.17.17.4:53 + 3 more... 10m</span><br><span class="line"></span><br><span class="line">[root@k8s-master-128 coredns]# kubectl -n kube-system get configmap coredns</span><br><span class="line">NAME DATA AGE</span><br><span class="line">coredns 1 12m</span><br></pre></td></tr></table></figure>
<p>CoreDNS所创建的服务均已正常启动。</p>
<h3 id="12-4、测试CoreDNS"><a href="#12-4、测试CoreDNS" class="headerlink" title="12.4、测试CoreDNS"></a>12.4、测试CoreDNS</h3><p>在安装完Kubernetes cluster环境后，如何验证coreDNS是否在正常工作?这是一项很重要的工作，将会影响将来在容器中部署的服务能否被正常调用。</p>
<p>我们可以通过创建一个busybox 的pod，再在busybox里去解析服务名的方式来验证coreDNS是否正常工作。</p>
<p>具体可参考kubernetes官方文档<a href="https://kubernetes.io/docs/tasks/administer-cluster/dns-debugging-resolution/" target="_blank" rel="noopener">《Debugging DNS Resolution》</a></p>
<p><strong>busybox的yaml文件：</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-128 coredns]# cat busybox.yaml</span><br><span class="line">apiVersion: v1</span><br><span class="line">kind: Pod</span><br><span class="line">metadata:</span><br><span class="line">  name: busybox</span><br><span class="line">  namespace: default</span><br><span class="line">spec:</span><br><span class="line">  containers:</span><br><span class="line">  - name: busybox</span><br><span class="line">    image: busybox:1.28</span><br><span class="line">    command:</span><br><span class="line">      - sleep</span><br><span class="line">      - &quot;3600&quot;</span><br><span class="line">    imagePullPolicy: IfNotPresent</span><br><span class="line">  restartPolicy: Always</span><br></pre></td></tr></table></figure></p>
<p><strong>创建Buxybox pod：</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-128 coredns]# kubectl create -f busybox.yaml</span><br><span class="line">pod/busybox created</span><br><span class="line">[root@k8s-master-128 coredns]# kubectl get pods busybox</span><br><span class="line">NAME READY STATUS RESTARTS AGE</span><br><span class="line">busybox 1/1 Running 0 26s</span><br></pre></td></tr></table></figure></p>
<p><strong>busybox的resolv.conf内容：</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-128 coredns]# kubectl exec busybox cat /etc/resolv.conf</span><br><span class="line">nameserver 10.0.0.2</span><br><span class="line">search default.svc.cluster.local svc.cluster.local cluster.local</span><br><span class="line">options ndots:5</span><br></pre></td></tr></table></figure></p>
<p><strong>在busybox 的pod里解析不同名字空间的服务：</strong><br>解析规则是：my-svc.my-namespace.svc.cluster.local<br>因此每个空间的服务都需要指明自己所在的名字空间才可进行访问<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-128 coredns]# kubectl exec -it busybox nslookup kubernetes.default</span><br><span class="line">Server: 10.0.0.2</span><br><span class="line">Address 1: 10.0.0.2 kube-dns.kube-system.svc.cluster.local</span><br><span class="line"></span><br><span class="line">Name: kubernetes</span><br><span class="line">Address 1: 10.0.0.1 kubernetes.default.svc.cluster.local</span><br><span class="line">[root@k8s-master-128 coredns]# kubectl exec -it busybox nslookup kube-dns.kube-system</span><br><span class="line">Server: 10.0.0.2</span><br><span class="line">Address 1: 10.0.0.2 kube-dns.kube-system.svc.cluster.local</span><br><span class="line"></span><br><span class="line">Name: kube-dns.kube-system</span><br><span class="line">Address 1: 10.0.0.2 kube-dns.kube-system.svc.cluster.local</span><br></pre></td></tr></table></figure></p>
<p>实验证明，用 <code>my-svc.my-namespace.svc.cluster.local</code>方法即可访问服务。</p>
<p><strong>在busybox 的pod里解析公网：</strong><br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">[root@k8s-master-128 coredns]# kubectl exec -it busybox nslookup qq.com</span><br><span class="line">Server: 10.0.0.2</span><br><span class="line">Address 1: 10.0.0.2 kube-dns.kube-system.svc.cluster.local</span><br><span class="line"></span><br><span class="line">Name: qq.com</span><br><span class="line">Address 1: 111.161.64.48 dns48.online.tj.cn</span><br><span class="line">Address 2: 111.161.64.40 dns40.online.tj.cn</span><br><span class="line">[root@k8s-master-128 coredns]# kubectl exec -it busybox nslookup www.baidu.com</span><br><span class="line">Server: 10.0.0.2</span><br><span class="line">Address 1: 10.0.0.2 kube-dns.kube-system.svc.cluster.local</span><br><span class="line"></span><br><span class="line">Name: www.baidu.com</span><br><span class="line">Address 1: 220.181.38.150</span><br><span class="line">Address 2: 220.181.38.149</span><br></pre></td></tr></table></figure></p>
<p>在busybox 的pod里解析外部IP地址 ，按照前文CoreDNS的配置，是通过pod所在node上的/etc/resolv.conf 来代理解析的。<br>通过以上例子可见，coredns工作正常。coredns既可以管理新生成的service的域名，又可以解析出外部域名。</p>
<p>参考文章：</p>
<ul>
<li><a href="https://www.kubernetes.org.cn/4105.html" target="_blank" rel="noopener">Kubernetes-基于flannel的集群网络</a></li>
<li><a href="https://www.kubernetes.org.cn/4508.html" target="_blank" rel="noopener">Kubernetes-docker垃圾清理</a></li>
<li><a href="https://www.kubernetes.org.cn/4058.html" target="_blank" rel="noopener">Kubernetes-DashBoard用户界面</a></li>
</ul>

      
    </div>

    

    
    
    

    <div>
      
        <div>
    
        <div style="text-align:center;color: #ccc;font-size:14px;">-------------本文结束<i class="fa fa-paw"></i>感谢您的阅读-------------</div>
    
</div>

<div>    
 
 
    <ul class="post-copyright">
      <li class="post-copyright-author">
          <strong>本文作者：</strong>开元
      </li>
      <li class="post-copyright-link">
        <strong>本文链接：</strong>
        <a href="/2019/06/11/kubernetes系列之《集群部署（下）》.html" title="kubernetes系列之《集群部署（下）》.md">2019/06/11/kubernetes系列之《集群部署（下）》.html</a>
      </li>
      <li class="post-copyright-license">
        <strong>版权声明： </strong>
        <!--Copyright©2018 NICKSORS.CC 版权所有 未经许可 请勿转载 -->
	本博客所有文章除特别声明外，均采用 <a href="http://creativecommons.org/licenses/by-nc-sa/3.0/cn/" rel="external nofollow" target="_blank">CC BY-NC-SA 3.0 CN</a> 许可协议。转载请注明出处!
      </li>
    </ul>
  
</div>

      
    </div>

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Kubernetes/" rel="tag"><i class="fa fa-tag"></i> Kubernetes</a>
          
            <a href="/tags/etcd/" rel="tag"><i class="fa fa-tag"></i> etcd</a>
          
            <a href="/tags/flanneld/" rel="tag"><i class="fa fa-tag"></i> flanneld</a>
          
            <a href="/tags/SSL/" rel="tag"><i class="fa fa-tag"></i> SSL</a>
          
            <a href="/tags/Docker/" rel="tag"><i class="fa fa-tag"></i> Docker</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2019/06/11/kubernetes系列之《集群部署（上）》.html" rel="next" title="kubernetes系列之《集群部署（上）》.md">
                <i class="fa fa-chevron-left"></i> kubernetes系列之《集群部署（上）》.md
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2019/06/14/kubernetes系列之《使用Kubeadm快速部署集群》.html" rel="prev" title="kubernetes系列之《使用Kubeadm快速部署集群》">
                kubernetes系列之《使用Kubeadm快速部署集群》 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/static/images/stark.jpg"
                alt="开元" />
            
              <p class="site-author-name" itemprop="name">开元</p>
              <p class="site-description motion-element" itemprop="description">知识管理，时间管理，自我管理</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">35</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">8</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">36</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  <a href="https://github.com/nicksors" target="_blank" title="GitHub"><i class="fa fa-fw fa-github"></i>GitHub</a>
                  
                </span>
              
            </div>
          

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-inline">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                Links
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="https://www.hi-linux.com/" title="运维之美" target="_blank">运维之美</a>
                  </li>
                
              </ul>
            </div>
          

          
            
          
          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#七、部署Master组件"><span class="nav-number">1.</span> <span class="nav-text">七、部署Master组件</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#7-1、获取二进制包"><span class="nav-number">1.1.</span> <span class="nav-text">7.1、获取二进制包</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-2、部署二进制文件"><span class="nav-number">1.2.</span> <span class="nav-text">7.2、部署二进制文件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-3、生成Kubeconfig文件"><span class="nav-number">1.3.</span> <span class="nav-text">7.3、生成Kubeconfig文件</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#7-3-1、api-server认证方式"><span class="nav-number">1.3.1.</span> <span class="nav-text">7.3.1、api-server认证方式</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-3-2、创建配置文件"><span class="nav-number">1.3.2.</span> <span class="nav-text">7.3.2、创建配置文件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-3-3、查看配置文件"><span class="nav-number">1.3.3.</span> <span class="nav-text">7.3.3、查看配置文件</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-4、启动Master组件"><span class="nav-number">1.4.</span> <span class="nav-text">7.4、启动Master组件</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#7-4-1、启动kube-apiserver"><span class="nav-number">1.4.1.</span> <span class="nav-text">7.4.1、启动kube-apiserver</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-4-2、启动kube-controller-manager"><span class="nav-number">1.4.2.</span> <span class="nav-text">7.4.2、启动kube-controller-manager</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#7-4-3、启动kube-sheduler"><span class="nav-number">1.4.3.</span> <span class="nav-text">7.4.3、启动kube-sheduler</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#7-5、查看组件运行状态"><span class="nav-number">1.5.</span> <span class="nav-text">7.5、查看组件运行状态</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#八、部署Node组件"><span class="nav-number">2.</span> <span class="nav-text">八、部署Node组件</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#8-1、创建Token租户并绑定角色"><span class="nav-number">2.1.</span> <span class="nav-text">8.1、创建Token租户并绑定角色</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-2、部署Kubelet"><span class="nav-number">2.2.</span> <span class="nav-text">8.2、部署Kubelet</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#8-2-1、启动Kubelet组件"><span class="nav-number">2.2.1.</span> <span class="nav-text">8.2.1、启动Kubelet组件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8-2-2、k8s集群为kubelet颁发证书"><span class="nav-number">2.2.2.</span> <span class="nav-text">8.2.2、k8s集群为kubelet颁发证书</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8-2-3、查看Node节点加入k8s集群"><span class="nav-number">2.2.3.</span> <span class="nav-text">8.2.3、查看Node节点加入k8s集群</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#8-2-4、查看Node节点签发的证书"><span class="nav-number">2.2.4.</span> <span class="nav-text">8.2.4、查看Node节点签发的证书</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#8-3、部署kube-proxy"><span class="nav-number">2.3.</span> <span class="nav-text">8.3、部署kube-proxy</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#九、部署一个测试示例"><span class="nav-number">3.</span> <span class="nav-text">九、部署一个测试示例</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#9-1、创建一个Nginx-pods"><span class="nav-number">3.1.</span> <span class="nav-text">9.1、创建一个Nginx pods</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#9-2、创建一个services"><span class="nav-number">3.2.</span> <span class="nav-text">9.2、创建一个services</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#9-3、访问services"><span class="nav-number">3.3.</span> <span class="nav-text">9.3、访问services</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#十、部署Web-UI（Dashboard）"><span class="nav-number">4.</span> <span class="nav-text">十、部署Web UI（Dashboard）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#10-1、获取YAML文件"><span class="nav-number">4.1.</span> <span class="nav-text">10.1、获取YAML文件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#10-2、更改YAML文件"><span class="nav-number">4.2.</span> <span class="nav-text">10.2、更改YAML文件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#10-3、执行部署"><span class="nav-number">4.3.</span> <span class="nav-text">10.3、执行部署</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#10-4、UI界面"><span class="nav-number">4.4.</span> <span class="nav-text">10.4、UI界面</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#十一、部署多Master节点集群"><span class="nav-number">5.</span> <span class="nav-text">十一、部署多Master节点集群</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#11-1、部署Master组件"><span class="nav-number">5.1.</span> <span class="nav-text">11.1、部署Master组件</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#11-1-1、拷贝文件"><span class="nav-number">5.1.1.</span> <span class="nav-text">11.1.1、拷贝文件</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#11-1-2、启动组件"><span class="nav-number">5.1.2.</span> <span class="nav-text">11.1.2、启动组件</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#11-2、Nginx负载Master节点"><span class="nav-number">5.2.</span> <span class="nav-text">11.2、Nginx负载Master节点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#11-3、Node节点配置使用"><span class="nav-number">5.3.</span> <span class="nav-text">11.3、Node节点配置使用</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#11-4、Keepalived实现Nginx高可用"><span class="nav-number">5.4.</span> <span class="nav-text">11.4、Keepalived实现Nginx高可用</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#11-4-1、Keepalived安装与配置"><span class="nav-number">5.4.1.</span> <span class="nav-text">11.4.1、Keepalived安装与配置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#11-4-2、故障模拟测试"><span class="nav-number">5.4.2.</span> <span class="nav-text">11.4.2、故障模拟测试</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#11-5、k8s集群接入负载均衡使用"><span class="nav-number">5.5.</span> <span class="nav-text">11.5、k8s集群接入负载均衡使用</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#11-5-1、更改Nginx配置"><span class="nav-number">5.5.1.</span> <span class="nav-text">11.5.1、更改Nginx配置</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#11-5-2、Node节点配置使用"><span class="nav-number">5.5.2.</span> <span class="nav-text">11.5.2、Node节点配置使用</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#11-5-3、K8集群状态"><span class="nav-number">5.5.3.</span> <span class="nav-text">11.5.3、K8集群状态</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#十二、部署集群内部DNS解析服务（CoreDNS）"><span class="nav-number">6.</span> <span class="nav-text">十二、部署集群内部DNS解析服务（CoreDNS）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#12-1、下载CoreDNS部署文件"><span class="nav-number">6.1.</span> <span class="nav-text">12.1、下载CoreDNS部署文件</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#12-2、部署CoreDNS"><span class="nav-number">6.2.</span> <span class="nav-text">12.2、部署CoreDNS</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#12-3、查看CoreDNS状态"><span class="nav-number">6.3.</span> <span class="nav-text">12.3、查看CoreDNS状态</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#12-4、测试CoreDNS"><span class="nav-number">6.4.</span> <span class="nav-text">12.4、测试CoreDNS</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
<div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">开元</span>


  

  
</div>



<div class="powered-by">
<i class="fa fa-user-md"></i><span id="busuanzi_container_site_uv">
  访问用户:<span id="busuanzi_value_site_uv"></span>
</span>
</div>


  <span class="post-meta-divider">|</span>


<div class="powered-by">
<i class="fa fa-eye"></i><span id="busuanzi_container_site_pv">
   访问量:<span id="busuanzi_value_site_pv"></span>
</span>
</div>


  <span class="post-meta-divider">|</span>


<div class="theme-info">
  <div class="powered-by"></div>
  <span class="post-count">全站共68.6k字</span>
</div>

<!--
<span class="post-meta-divider">|</span>


  <div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div>




  <span class="post-meta-divider">|</span>



  <div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/theme-next/hexo-theme-next">NexT.Mist</div>



-->

        








        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>


























  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=6.3.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=6.3.0"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=6.3.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=6.3.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=6.3.0"></script>



  



	





  





  










  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  

  

  
  

  

  

  

  

  

</body>
</html>
<!-- 页面点击小红心 -->
<!--<script type="text/javascript" src="/js/src/love.js"></script>-->
