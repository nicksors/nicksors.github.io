<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[Docker系列之《Dockerfile构建MySQL镜像》]]></title>
    <url>%2F2018%2F06%2F19%2FDocker%E7%B3%BB%E5%88%97%E4%B9%8B%E3%80%8ADockerfile%E6%9E%84%E5%BB%BAMySQL%E9%95%9C%E5%83%8F%E3%80%8B.html</url>
    <content type="text"><![CDATA[前言: 学会使用Dockerfile制作自己需要的镜像是必备的技能，本文就通过实战的方式展示如何通过Dockerfile来制作MySQL镜像。 1、编写镜像Dockerfile（1）创建Dockerfile文件，并在文件开始位置添加使用#注释的描述信息：123# 名称：容器化的MySQL# 用途：用作后端数据库持久化服务# 创建时间：2018.06.11 （2）定义基础镜像1FROM centos （3）声明维护者信息1MAINTAINER tanshuai 1432753451@qq.com （4）定义工作目录1WORKDIR /root/ （5）安装相关软件123RUN yum -y install wgetRUN wget http://repo.mysql.com/mysql-community-release-el7-5.noarch.rpmRUN rpm -ivh /root/mysql-community-release-el7-5.noarch.rpm （6）使用yum安装MySQL服务123RUN yum install mysql-server -y# 安装好MySQL后，默认并没有建立数据库，需要使用musql_install_db创建一个数据库：RUN mysql_install_db --user=mysql （7）通过环境变量指定MySQL使用的用户名和密码，MySQL拥有一个默认的用户root，但root用户默认只能在本地访问，所以这里定一了一个额外的用户test：12ENV MYSQL_USER testENV MYSQL_PASS =mypassword （8）让容器支持中文，centos容器默认是不支持中文的1ENV LC_ALL en_US.UTF-8 （9）导出3306端口（这里是MYSQL使用的端口），以后外部使用可以访问它1EXPOSE 3306 （10）定义默认的启动命令，这里使用一个脚本来启动MySQL123ADD run.sh /root/run.shRUN chmod u+x /root/run.shCMD /root/run.sh 2、完整的Dockerfile：123456789101112131415161718# 名称：容器化的MySQL# 用途：用作后端数据库持久化服务# 创建时间：2018.06.11FROM centosMAINTAINER tanshuai 1432753451@qq.comWORKDIR /root/RUN yum -y install wgetRUN wget http://repo.mysql.com/mysql-community-release-el7-5.noarch.rpmRUN rpm -ivh /root/mysql-community-release-el7-5.noarch.rpmRUN yum install mysql-server -yRUN mysql_install_db --user=mysqlENV MYSQL_USER testENV MYSQL_PASS =mypasswordENV LC_ALL en_US.UTF-8EXPOSE 3306ADD run.sh /root/run.shRUN chmod u+x /root/run.shCMD /root/run.sh （1）run.sh定义了容器的默认启动行为，这里只是拉起MySQL，其内容为：12#!/bin/bashmysqld_safe 3、构建和上传镜像Dockerfile和必要的文件都准备好了，接下来就可以使用docker build 命令来后街镜像了：1234567891011121314151617$ docker build -t docker.io/nicksors/mysql:latest /root/build_images/build_mysqlSending build context to Docker daemon 3.584 kBStep 1 : FROM centos ---&gt; 0584b3d2cf6dStep 2 : MAINTAINER tanshuai 1432753451@qq.com ---&gt; Running in ebbb7a8b003a ---&gt; 19316ea8b554Removing intermediate container ebbb7a8b003aStep 3 : WORKDIR /root/ ---&gt; Running in 83e6594d48db ---&gt; dd4a9e06196c~~~中间太长自动略过~~~Step 15 : CMD /root/run.sh ---&gt; Running in 98e4b96d656e ---&gt; b340df2bc01fRemoving intermediate container 98e4b96d656eSuccessfully built b340df2bc01f 4、启动MySQL容器12345$ docker run -d -p 3306:3306 --name=mysql docker.io/nicksors/mysql /root/run.shabc07ad4db8eef4d38d7b7abda99d6609f9108704aa8f45e0499459610ccef2f$ docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESabc07ad4db8e docker.io/nicksors/mysql "/root/run.sh" 52 seconds ago Up 51 seconds 0.0.0.0:3306-&gt;3306/tcp mysql 构建好镜像之后，通过docker push命令将镜像提交到Docker Hub： 123456789101112$ docker push docker.io/nicksors/mysqla2db66ccbd56: Pushed 157fa65fbf3b: Pushed 8ed28c549a06: Pushed 4ded80e382c6: Pushing [=====&gt; ] 49.42 MB/423.7 MBdee17d2fbb38: Pushed 0074ce8e9d38: Pushed d2193e3db81f: Pushing [=====================&gt; ] 46.14 MB/109.5 MB97ca462ad9ee: Mounted from library/centos 97ca462ad9ee: Preparing 97ca462ad9ee: Mounted from library/centos latest: digest: sha256:d0f8c127884437a8aa8798340be021b8dd56929cfab51bf4822afd435f8ce0a6 size: 1975 现在MySQL镜像就创建好了，并且可以在任何可以上网的机器上从Docker Hub拉取。]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Dockerfile</tag>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python系列之《Django-DRF-视图的演变（二）》]]></title>
    <url>%2F2018%2F06%2F16%2FPython%E7%B3%BB%E5%88%97%E4%B9%8B%E3%80%8ADjango-DRF-%E8%A7%86%E5%9B%BE%E7%9A%84%E6%BC%94%E5%8F%98%EF%BC%88%E4%BA%8C%EF%BC%89%E3%80%8B.html</url>
    <content type="text"><![CDATA[前言：本文是“Python系列之《Django-DRF-序列化模型（一）》”的姊妹篇，其中示例所用的内容也继承了它，这篇文章是比较高阶的内容，适合有一定基础的同学查阅。 视图的演变版本一（底层方法）这种方法只需要看得懂即可，因为太底层了，后面写代码不会用这种方式 1、撰写视图： 写一个视图，支持：GET all、GET one、POST、PUT、DELETE这五个操作。 $ vim idcs/views.py123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354from django.http import HttpResponsefrom rest_framework.renderers import JSONRendererfrom rest_framework.parsers import JSONParserfrom .models import Idcfrom .serializers import IdcSerializerclass JSONResponse(HttpResponse): def __init__(self, data, **kwargs): kwargs.setdefault('content_type', 'application/json') content = JSONRenderer().render(data) super(JSONResponse, self).__init__(content=content, **kwargs)def idc_list(request, *args, **kwargs): if request.method == 'GET': quertset = Idc.objects.all() serializer = IdcSerializer(quertset,many=True) return JSONResponse(serializer.data) # content = JSONRenderer().render(serializer.data) # return HttpResponse(content=content,content_type="application/json") elif request.method == 'POST': content = JSONParser().parse(request) serializer = IdcSerializer(data=content) if serializer.is_valid(): serializer.save() return JSONResponse(serializer.data) return HttpResponse('')def idc_detail(request, pk, *args, **kwargs): try: idc = Idc.objects.get(pk=pk) except Idc.DoesNotExist: return HttpResponse(status=404) if request.method == 'GET': serializer = IdcSerializer(idc) return JSONResponse(serializer.data) elif request.method == 'PUT': content = JSONParser().parse(request) serializer = IdcSerializer(idc, data=content) if serializer.is_valid(): serializer.save() return JSONResponse(serializer.data) return JSONResponse(serializer.errors,status=400) elif request.method == 'DELETE': idc.delete() return HttpResponse(status=204)# 代码说明：1. JSONResponse改写了Django里默认的，目的是处理POST提交的数据，将数据转换成JSON后方便处理。2. idc_list可以通过HttpResponse和改写的JSONResponse两种方法来返回给前端。3. idc_detail函数设计接受一个pk，这个pk是一个id，通过查询到ID后，进行GET、PUT、DELETE操作。 2、路由规则：$ vim idc/urls.py12345678from django.conf.urls import urlfrom idcs.views import idc_list,idc_detail########################### 版本一 ##############################urlpatterns = [ url('^idcs/$', idc_list, name='idc_list'), url('^idcs/(?P&lt;pk&gt;[0-9]+)/$', idc_detail, name='idc_detail')] 3、GET请求（获取所有数据）： 本文使用Postman工具来进行Http请求的提交操作，每一次提交请求后，该工具都会有Status字段显示请求的状态码，比较方便。 4、POST请求（创建一个数据）： 5、GET请求（使用pk指定获取一个资源信息）： 6、PUT更新（更新一个资源的信息）： 7、DELETE删除（删除一个资源）： 版本二（基于函数视图的@api_view装饰器）1、撰写视图：$ vim idcs/views.py1234567891011121314151617181920212223242526272829303132333435363738394041424344########################### 版本二 ##############################from rest_framework.decorators import api_view #导入api_viewfrom rest_framework import status # 导入status，返回状态使用这个模块from rest_framework.response import Response # DRF封装好的方法Response@api_view(["GET","POST"])def idc_list_v2(request, *args, **kwargs): if request.method == 'GET': queryset = Idc.objects.all() serializer = IdcSerializer(queryset, many=True) return Response(serializer.data) elif request.method == 'POST': serializer = IdcSerializer(data=request.data) if serializer.is_valid(): serializer.save() return Response(serializer.data, status=status.HTTP_201_CREATED) return Response(serializer.data, status=status.HTTP_404_NOT_FOUND)@api_view(["GET", "PUT", "DELETE"])def idc_detail_v2(request, pk, *args, **kwargs): try: idc = Idc.objects.get(pk=pk) except Idc.DoesNotExist: return HttpResponse(status=status.HTTP_404_NOT_FOUND) if request.method == 'GET': serializer = IdcSerializer(idc) return Response(serializer.data) elif request.method == 'PUT': serializer = IdcSerializer(idc, data=request.data) if serializer.is_valid(): serializer.save() return Response(serializer.data) return Response(serializer.errors, status=status.HTTP_404_NOT_FOUND) elif request.method == 'DELETE': idc.delete() return HttpResponse(status=status.HTTP_204_NO_CONTENT)# 代码说明：1. @api_view()，传入一个列表作为参数，这个列表里写入具体的方法，如["GET", "PUT", "DELETE"]。api_view之会允许你写入的Http方法进行交互。没有写的就会禁止交互。2. status.HTTP_404_NOT_FOUND，status模块可以返回你想要给前端的状态。3. Response，这是drf给我们封装好的方法，它会将模板和数据一并返回给前端，所以你在前端能看见drf的页面了。 2、路由规则：$ vim idc/urls.py12345678910from django.conf.urls import urlfrom idcs.views import idc_list,idc_detailfrom . import views ########################### 版本二 ##############################urlpatterns = [ url('^idcs/$', views.idc_list_v2, name='idc_list'), url('^idcs/(?P&lt;pk&gt;[0-9]+)/$', views.idc_detail_v2)] 3、GET请求（请求所有列表）： 4、POST请求（提交数据进行创建操作）：注意：需要指定POST请求的数据类型为JSON！！！ 5、GET请求（通过id获取数据）：直接通过浏览器访问的话，就能看到Response渲染给前端的页面。 6、PUT请求（更新数据）： 7、DELETE操作 第二版本完事儿~ Api Root截至目前，你在访问跟站点的时候，应该是会出错的，因为我们没有定义访问跟站点需要显示哪些资源。 因此，我们这里介绍下Api Root，它是干什么的呢？先简单理解下：在访问跟站点的时候，为我们列出当前有哪些资源。如果你还是不理解，那且看下面的操作。 1、撰写视图：$ vim idc/views.py123456789101112from rest_framework.reverse import reverse@api_view(["GET"])def api_root(request, format=None, *args, **kwargs): return Response(&#123; "idcs": reverse("idc_list", request=request, format=format) &#125;)代码说明：1. reverse，drf封装好的方法，跟Django里的reverse功能一样；第一个参数："idc_list"是路由里的Namespace名称，使用它的好处我想不用再说了。2. 通过Response返回一个字典类型。 2、路由规则：$ vim idc/urls.py123456789101112########################### 版本二 ##############################from . import viewsfrom rest_framework.urlpatterns import format_suffix_patternsurlpatterns = [ url("^$",views.api_root), url('^idcs/$', views.idc_list_v2, name='idc_list'), url('^idcs/(?P&lt;pk&gt;[0-9]+)/$', views.idc_detail_v2, name='idc_detail')]urlpatterns = format_suffix_patterns(urlpatterns)代码说明：1. 所有的urlpatterns通过drf里的方法format_suffix_patterns实例化后，再付给urlpatterns，达到能渲染跟站点路由的效果。 3、首页访问显示： 具体的效果如下 那有个问题，如果这个平台的app非常多，项目非常大，导致url也会非常多，这时候这个列表该如何维护呢？ 只能一条条增加，且后期维护成本较大，这算是一个缺点。 版本三（基于类视图APIView类）1、撰写视图：$ vim idcs/views.py12345678910111213141516171819202122232425262728293031323334353637383940414243444546########################### 版本三 ##############################from rest_framework.views import APIViewfrom django.http import Http404class IdcList(APIView): def get(self,request, format=None): queryset = Idc.objects.all() serializer = IdcSerializer(queryset, many=True) return Response(serializer.data) def post(self,request, format=None): serializer = IdcSerializer(data=request.data) if serializer.is_valid(): serializer.save() return Response(serializer.data, status=status.HTTP_201_CREATED) return Response(serializer.data, status=status.HTTP_404_NOT_FOUND)class IdcDetail(APIView): def get_object(self, pk): try: return Idc.objects.get(pk=pk) except Idc.DoesNotExist: raise Http404 def get(self, request, pk, format=None): idc = self.get_object(pk) serializer = IdcSerializer(idc) return Response(serializer.data) def put(self,request, pk, format=None): idc = self.get_object(pk) serializer = IdcSerializer(idc, data=request.data) if serializer.is_valid(): serializer.save() return Response(serializer.data) return Response(serializer.errors, status=status.HTTP_404_NOT_FOUND) def delete(self, request, pk, format=None): idc = self.get_object(pk) idc.delete() return HttpResponse(status=status.HTTP_204_NO_CONTENT)代码说明：1. 使用类视图，定义两个类并继承APIView类视图；2. 在类视图里编写：增删改查方法，通过HttpResponse返回状态。 通过源码能看出，APIView是继承的Django View视图的。 2、路由规则：$ vim idc/urls.py123456789########################### 版本三 ##############################from . import viewsfrom rest_framework.urlpatterns import format_suffix_patternsurlpatterns = [ url("^$",views.api_root), url('^idcs/$', views.IdcList.as_view(), name='idc_list'), url('^idcs/(?P&lt;pk&gt;[0-9]+)/$', views.IdcDetail.as_view(), name='idc_detail') #调用类视图]urlpatterns = format_suffix_patterns(urlpatterns) 从这个版本往后，我就不一个个截图了，接口操作上面已经说得很详细。 版本四（使用混合 mixins）这一版本的功能更为高级，使用mixins来实现，往下看！ 1、撰写视图：$ vim idcs/views.py1234567891011121314151617181920212223242526272829303132333435363738394041424344454647########################### 版本四（混合:mixins） ##############################from rest_framework import mixins, generics # 导入相应模块class IdcList_V4(generics.GenericAPIView, mixins.ListModelMixin, mixins.CreateModelMixin): # 继承generics和mixins里的方法，称之为“混合” queryset = Idc.objects.all() # 继承了generics，通过通过成员属性的形式传入参数 serializer_class = IdcSerializer # 继承了generics，通过通过成员属性的形式传入参数 def get(self, request, *args, **kwargs): # 第四版的 get和post方法还得自己写 return self.list(request, *args, **kwargs) def post(self, request, *args, **kwargs): return self.create(request, *args, **kwargs)class IdcDetail_V4(generics.GenericAPIView, mixins.RetrieveModelMixin, mixins.UpdateModelMixin, mixins.DestroyModelMixin): # detail类，继承mixins的检索、更新、删除等类方法 queryset = Idc.objects.all() serializer_class = IdcSerializer def get(self, request, *args, **kwargs): return self.retrieve(request, *args, **kwargs) def put(self, request, *args, **kwargs): return self.update(request, *args, **kwargs) def delete(self, request, *args, **kwargs): # 写好调用的方法 return self.destroy(request, *args, **kwargs)代码说明：1. 为什么要继承mixins.RetrieveModelMixin,mixins.UpdateModelMixin,mixins.DestroyModelMixin等这一堆方法呢？答：比如我们自定义写了delete方法，而这个方法会自动、只能的去调用mixins.DestroyModelMixin这个类里面的动作，这里给你看看DestroyModelMixin的源码就明白了。class DestroyModelMixin(object): """ Destroy a model instance. """ def destroy(self, request, *args, **kwargs): instance = self.get_object() self.perform_destroy(instance) return Response(status=status.HTTP_204_NO_CONTENT) def perform_destroy(self, instance): instance.delete() &lt;==在这里，DestroyModelMixin指定执行了一个delete动作，这也就达到了，前端调用我们自定义写的delete方法，就相当于在调用这里。 在版本三中，queryset和serializer属性都是通过自己声明去使用的；版本四继承使用混合继承了generics，通过查看generics源码发现如下：12345class GenericAPIView(views.APIView):··· queryset = None serializer_class = None··· 由上可看出，generics将queryset和serializer通过成员属性的形式抽离出来了，那我们只需要将这两个成员属性声明即可。 2、路由规则：$ vim idc/urls.py123456789########################### 版本四 ##############################from . import viewsfrom rest_framework.urlpatterns import format_suffix_patternsurlpatterns = [ url("^$",views.api_root), url('^idcs/$', views.IdcList_V4.as_view(), name='idc_list'), url('^idcs/(?P&lt;pk&gt;[0-9]+)/$', views.IdcDetail_V4.as_view(), name='idc_detail')]urlpatterns = format_suffix_patterns(urlpatterns) 版本五（使用混合高级版）1、撰写视图：$ vim idcs/views.py123456789########################### 版本五(使用混合高级版) ##############################class IdcList_V5(generics.ListCreateAPIView): queryset = Idc.objects.all() serializer_class = IdcSerializerclass IdcDetail_V5(generics.RetrieveUpdateDestroyAPIView): queryset = Idc.objects.all() serializer_class = IdcSerializer 这几行代码搞定上面所有功能，只需要传入queryset和serializer即可，这什么原理呢？且看我来解释： 1、第四版本中，我们继承了generics.GenericAPIView类视图，自己写了两个get和post方法对吧，那generics的另一个方法把这两个事情也干了，我们只需要继承即可。2、对的，这个方法就是generics.ListCreateAPIView，我们且看看它的源码，你就明白了1234567891011class ListCreateAPIView(mixins.ListModelMixin, mixins.CreateModelMixin, GenericAPIView): """ Concrete view for listing a queryset or creating a model instance. """ def get(self, request, *args, **kwargs): return self.list(request, *args, **kwargs) def post(self, request, *args, **kwargs): return self.create(request, *args, **kwargs) 在上面源码里我们看到，ListCreateAPIView直接继承了mixins.ListModelMixin,mixins.CreateModelMixin和GenericAPIView视图，那我们直接用它就好了呀，哈哈，这就是第五版本的进化点。 3、继承generics.RetrieveUpdateDestroyAPIView的方法类似，因为它也封装好了get、put、patch（更新）和delete操作。 真是简单便捷，卧凑，下面还有更简单的，咱们一步步往下看。 2、路由规则：$ vim idc/urls.py1234567########################### 版本五 ##############################urlpatterns = [ url("^$",views.api_root), url('^idcs/$', views.IdcList_V5.as_view(), name='idc_list'), url('^idcs/(?P&lt;pk&gt;[0-9]+)/$', views.IdcDetail_V5.as_view(), name='idc_detail')]urlpatterns = format_suffix_patterns(urlpatterns) 版本六（视图集 ViewSet）1、撰写视图：$ vim idcs/views.py1234567891011########################### 版本六（视图集 ViewSet） ##############################from rest_framework import viewsetsclass IdcListViewset(viewsets.GenericViewSet, mixins.ListModelMixin, mixins.CreateModelMixin, mixins.RetrieveModelMixin, mixins.DestroyModelMixin, mixins.UpdateModelMixin,): queryset = Idc.objects.all() serializer_class = IdcSerializer 第六版的视图进化点很明显就能看出来吧，在views里就写了一个内视图，之前的所有版本都是写一个List和一个Detail视图的。 IdcListViewset继承了viewsets.GenericViewSet，其他的方法都是mixins的，跟第五版本一样，这些方法又封装好了相对应的如更新、删除、查询操作。真是便捷呀！ 值得一说的是viewsets.GenericViewSet继承了ViewSetMixin方法，从ViewSetMixin的源码里能看到可以改写as_view的信息，来达到定制路由的效果ViewSetMixin的源码部分如下：123456789class ViewSetMixin(object): @classonlymethod def as_view(cls, actions=None, **initkwargs): ······ if not actions: raise TypeError("The `actions` argument must be provided when " "calling `.as_view()` on a ViewSet. For example " "`.as_view(&#123;'get': 'list'&#125;)`") ······ 能看到在actions字段可以设置{‘get’: ‘list’}这样的路由规则，那且看路由规则的写法 2、路由规则：$ vim idc/urls.py1234567891011121314151617181920########################### 版本六 ############################### 定义了idc_list处理get和post两个路由请求idc_list = views.IdcListViewset.as_view(&#123; "get": "list", # 这里的“list”对应IdcListViewset里继承的mixins.ListModelMixin，而且post和下面的put等方法，也是需要一一对应 "post": "create"&#125;)# 定义了idc_detail处理get和put和delete请求idc_detail = views.IdcListViewset.as_view(&#123; "get": "retrieve", "put": "update", "delete": "destroy"&#125;)urlpatterns = [ url("^$",views.api_root), url('^idcs/$', idc_list, name='idc_list'), #&lt;==这里使用上面的定义即可 url('^idcs/(?P&lt;pk&gt;[0-9]+)/$', idc_detail, name='idc_detail')]urlpatterns = format_suffix_patterns(urlpatterns) 版本七 （终极大法：写项目选用此法）1、撰写视图：$ vim idcs/views.py123456########################### 版本七 ##############################from rest_framework import viewsetsclass IdcViewset_V7(viewsets.ModelViewSet): queryset = Idc.objects.all() serializer_class = IdcSerializer 根据版本五和版本六的继承套路，版本七直接继承了一个巨无霸（ModelViewSet），这个巨无霸将所有的功能都封装到一块。相当于把我们从第一版到第六版写的所有事情都干了，按照老规矩，我们来看看它的源码：1234567891011class ModelViewSet(mixins.CreateModelMixin, mixins.RetrieveModelMixin, mixins.UpdateModelMixin, mixins.DestroyModelMixin, mixins.ListModelMixin, GenericViewSet): &quot;&quot;&quot; A viewset that provides default `create()`, `retrieve()`, `update()`, `partial_update()`, `destroy()` and `list()` actions. &quot;&quot;&quot; pass 从源码中能看出，ModelViewSet所继承的视图类，我们在前面几个版本中都重点继承并介绍过。所以，你知道它的原理了吧！ 2、路由规则：$ vim idc/urls.py12345678########################### 版本七 ##############################from rest_framework.routers import DefaultRouterroute = DefaultRouter()route.register("idcs", views.IdcViewset_V7)urlpatterns = [ url(r'^', include(route.urls))] 最终版的规则使用了drf的DefaultRouter函数，通过实例化DefaultRouter得到route对象，使用route.register()你的app路由，有多个注册多个即可，使用也很简单。 本文由“Rock”布道，本站学习和整理发布。 如果你在阅读或使用文章中遇到问题，欢迎加入QQ群：32330026，我们是一群爱学习的人，期待与你一起学习进步。]]></content>
      <categories>
        <category>Python开发</category>
        <category>Django</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Django</tag>
        <tag>DRF</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python系列之《Django-DRF-序列化模型（一）》]]></title>
    <url>%2F2018%2F06%2F15%2FPython%E7%B3%BB%E5%88%97%E4%B9%8B%E3%80%8ADjango-DRF-%E5%BA%8F%E5%88%97%E5%8C%96%E6%A8%A1%E5%9E%8B%EF%BC%88%E4%B8%80%EF%BC%89%E3%80%8B.html</url>
    <content type="text"><![CDATA[前言：本文带领大家了解django-rest-framework “序列化模型”的一些使用及知识点，通过实战演示进一步让大家能简单看懂，并且上手操作，了解DRF的强大。 一、App创建与管理在讲解本文主题“序列化模型”之前，我们需要创建一个app来进行实际的演示，因此你想更深入的了解学习本文知识点的话，建议你跟着一起操作。 首先创建一个app：1$ python manage.py startapp idcs 随着项目越来越庞大，项目里的app越来越多，因此需要将所有app进行管理起来，管理方法如下 创建管理app的目录：12$ mkdir apps$ mv idcs apps 需要知道的是，创建的app也是一个python的模块，我们后面也可以将一些非app的模块放到这里面，目的是便于管理。 因为目录结构有了变化，Django找不到创建的app了，所以需要我们配置一下，告诉Django在哪里能找到我们创建的app。方法如下Django加载apps目录：123456789101112$ vim ops/settings.pyimport osimport sys # 先导入sys模块# Build paths inside the project like this: os.path.join(BASE_DIR, ...)BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))sys.path.insert(0, os.path.join(BASE_DIR, &apos;apps&apos;)) # 增加这一行INSTALLED_APPS = [······ &apos;idcs.apps.IdcsConfig&apos;, #在apps列表里添加刚刚创建的idcs app] 需要在Django的配置文件里加载它，这里使用sys模块将apps所在的路径插入到sys.path中，这样Django在寻找app的时候就知道去哪找了。 idcs创建urls.py： 上面通过startapp创建好app后，你会发现app里没有urls.py。嘿嘿嘿，如果没有这个文件，你启动Django项目试试？它保证不会任性不出错（讽刺）。。。 因此，我们需要自己来创建这个文件，并写下urlpatterns字段。123$ vim apps/idcs/urls.pyurlpatterns = [] 配置路由：app的导入和url问题都搞定了，接下来需要在全局urls.py文件里配置idcs这个app的路由关系12345$ vim ops/urls.pyurlpatterns = [ url(r&apos;^admin/&apos;, admin.site.urls), url(r&apos;^idcs/&apos;, include(&quot;idcs.urls&quot;)), # 默认无法识别，Pycharm工具配置自动识别方法：右击“apps”目录 --&gt;Mark --&gt;Source Root ] 安装DRF：配置好app后，我们顺便把DRF也安装和配置一下，非常简单快速。 1、安装1$ pip install django-rest-framework 2、配置Django加载DRFDjango使用drf比较简单，直接在apps列表里写入如下模块即可完成，后面就等着使用了。123456$ vim ops/settings.pyINSTALLED_APPS = [······ &apos;rest_framework&apos;,] 好，完事。 二、序列化模型2.1、同步Idc模型在models模型文件里创建字段如下，并使用下面给出的命令快速同步到数据库中123456789101112131415161718$ vim idcs/models.pyclass Idc(models.Model): name = models.CharField(&quot;机房名称&quot;,max_length=32) address = models.CharField(&quot;机房地址&quot;,max_length=256) phone = models.CharField(&quot;联系人&quot;,max_length=15) email = models.EmailField(&quot;邮件地址&quot;,default=&quot;null&quot;) letter = models.CharField(&quot;IDC简称&quot;,max_length=5) def __str__(self): return self.name class Meta: db_table = &apos;resource_idc&apos;$ python manage.py showmigrations$ python manage.py migrate$ python manage.py makemigrations idcs$ python manage.py migrate idcs 2.2、定义序列化类在idc app目录下新建一个文件serializers.py，因为是做序列化，而序列化是针对模型的，所以需要跟模型文件models.py在同一个目录下123456789101112131415$ vim idcs/serializers.pyfrom rest_framework import serializers # 导入这个模块，来使用序列化# 定义并编写序列化类class IdcSerializer(serializers.Serializer): &quot;&quot;&quot; Idc, 序列化类 &quot;&quot;&quot; id = serializers.IntegerField(read_only=True) # 处理只读 name = serializers.CharField(required=True, max_length=32) # 字段必须传, 最大限制32个字符 address = serializers.CharField(required=True, max_length=256) phone = serializers.CharField(required=True, max_length=15) email = serializers.CharField(required=True) letter = serializers.CharField(required=True, max_length=5) 2.3、使用序列化通过python mamage.py shell往IDC模型里添加两条记录 12345678910111213141516In [1]: from idcs.models import IdcIn [2]: idc = Idc()In [3]: idc.name = &apos;亦庄机房&apos;In [4]: idc.address = &apos;北京亦庄机房&apos;In [5]: idc.phone = &apos;12312341234&apos;In [6]: idc.email = &apos;nick@qq.com&apos;In [7]: idc.letter = &apos;yz&apos;In [8]: idc.save()In [9]:In [9]: idc.id = NoneIn [10]: idc.name = &apos;兆维机房&apos;In [11]: idc.address = &apos;兆维工业园&apos;In [12]: idc.phone = &apos;18512341234&apos;In [13]: idc.email = &apos;zw@qq.com&apos;In [14]: idc.letter = &apos;zw&apos;In [15]: idc.save() 2.3.1、正向序列化正向序列化的定义：从“数据库”里获取数据并序列化后返回标准JSON类型的数据给前端 具体使用序列化的操作如下：1234567891011121314151617181920212223242526In [17]: from idcs.serializers import IdcSerializer # 导入序列化类In [18]: idc = Idc.objects.get(pk=1) # 获取一条IDC信息，等待序列化In [19]: idcOut[19]: &lt;Idc: 亦庄机房&gt;In [20]: serializers = IdcSerializer(idc) # 将idc对象传给序列化类 进行序列化操作后存放到一个变量里，序列化完成。In [21]: serializers # 输出结果，会把序列化里的字段给打印出来Out[21]:IdcSerializer(&lt;Idc: 亦庄机房&gt;): id = IntegerField() name = CharField() address = CharField() phone = CharField() email = CharField() letter = CharField()In [23]: serializers.data # 通过.data能获取到所有的数据Out[23]: &#123;&apos;id&apos;: 1, &apos;name&apos;: &apos;亦庄机房&apos;, &apos;address&apos;: &apos;北京亦庄机房&apos;, &apos;phone&apos;: &apos;12312341234&apos;, &apos;email&apos;: &apos;nick@qq.com&apos;, &apos;letter&apos;: &apos;yz&apos;&#125;In [24]: a = serializers.dataIn [25]: type(a)Out[25]: rest_framework.utils.serializer_helpers.ReturnDict 能看到serializers.data的类型是一个ReturnDict，而我们最终需求是需要转换成Json类型返回给前端的，那如何转换呢？ 使用drf内置模块将结果转换成标准的json数据：1234567891011121314In [26]: from rest_framework.renderers import JSONRendererIn [27]: ?JSONRendererInit signature: JSONRenderer()Docstring: Renderer which serializes to JSON.File: ~/Projects/Python/v3/VirtualSource/venv/lib/python3.6/site-packages/rest_framework/renderers.pyType: typeIn [28]: jr = JSONRenderer() # 实例化In [29]: jr.render(serializers.data) # 使用render方法将结果转换成标准的Json数据Out[29]: b&apos;&#123;&quot;id&quot;:1,&quot;name&quot;:&quot;\xe4\xba\xa6\xe5\xba\x84\xe6\x9c\xba\xe6\x88\xbf&quot;,&quot;address&quot;:&quot;\xe5\x8c\x97\xe4\xba\xac\xe4\xba\xa6\xe5\xba\x84\xe6\x9c\xba\xe6\x88\xbf&quot;,&quot;phone&quot;:&quot;12312341234&quot;,&quot;email&quot;:&quot;nick@qq.com&quot;,&quot;letter&quot;:&quot;yz&quot;&#125;&apos;In [30]: content = jr.render(serializers.data) # 拿到这个数据，就可以直接返回给前端了。 正向序列化多条记录：1234567891011121314151617181920212223242526In [1]: from idcs.models import IdcIn [2]: from idcs.serializers import IdcSerializerIn [3]: Idc.objects.all()Out[3]: &lt;QuerySet [&lt;Idc: 亦庄机房&gt;, &lt;Idc: 兆维机房&gt;]&gt;In [4]: data = IdcSerializer(Idc.objects.all(), many=True) # 关键在于这一步，使用many=True声明传入的是多个object对象In [5]: dataOut[15]: IdcSerializer(&lt;QuerySet [&lt;Idc: 亦庄机房&gt;, &lt;Idc: 兆维机房&gt;]&gt;, many=True): id = IntegerField() name = CharField() address = CharField() phone = CharField() email = CharField() letter = CharField()In [6]: from rest_framework.renderers import JSONRendererIn [6]: content = JSONRenderer().render(data.data)In [7]: contentOut[7]: b&apos;[&#123;&quot;id&quot;:1,&quot;name&quot;:&quot;\xe4\xba\xa6\xe5\xba\x84\xe6\x9c\xba\xe6\x88\xbf&quot;,&quot;address&quot;:&quot;\xe5\x8c\x97\xe4\xba\xac\xe4\xba\xa6\xe5\xba\x84\xe6\x9c\xba\xe6\x88\xbf&quot;,&quot;phone&quot;:&quot;12312341234&quot;,&quot;email&quot;:&quot;nick@qq.com&quot;,&quot;letter&quot;:&quot;yz&quot;&#125;,&#123;&quot;id&quot;:2,&quot;name&quot;:&quot;\xe5\x85\x86\xe7\xbb\xb4\xe6\x9c\xba\xe6\x88\xbf&quot;,&quot;address&quot;:&quot;\xe5\x85\x86\xe7\xbb\xb4\xe5\xb7\xa5\xe4\xb8\x9a\xe5\x9b\xad&quot;,&quot;phone&quot;:&quot;18512341234&quot;,&quot;email&quot;:&quot;zw@qq.com&quot;,&quot;letter&quot;:&quot;zw&quot;&#125;]&apos; 小结：序列化的过程如下 mysql获取数据 queryset = Idc.objects.all() #获取单个或所有idc对象 content = JSORNRenderer().render(queryset) # 转换成标准Json数据 HttpResponse(content) # 返回给前端 重点：上面的小结里，能看到序列化的过程，那序列化还能做些什么事情呢？它可以验证前端传入过来的数据，并且添加、更新这些数据。 2.3.2、反向序列化反向序列化的定义：从“前端接口”接收添加的数据并序列化后返回一个object对象给后端，而且可以进行数据验证以及添加到数据库的操作。 编写序列化验证、创建、更新、保存规则：123456789101112131415161718192021222324252627282930$ vim idcs/serializers.pyfrom rest_framework import serializersfrom .models import Idc # 需要导入Idc模型class IdcSerializer(serializers.Serializer): &quot;&quot;&quot; Idc, 序列化类 &quot;&quot;&quot; id = serializers.IntegerField(read_only=True) # 处理只读 name = serializers.CharField(required=True, max_length=32) # 字段必须传, 最大限制32个字符 address = serializers.CharField(required=True, max_length=256) phone = serializers.CharField(required=True, max_length=15) email = serializers.CharField(required=True) letter = serializers.CharField(required=True, max_length=5) def create(self, validated_data): return Idc.objects.create(**validated_data) # 调用Idc模型进行create操作 def update(self, instance, validated_data): # 参数介绍：instance是当前的对象，validated_data是处理过的干净数据 &apos;&apos;&apos; update方法可以允许修改什么字段，如果有不需要修改的字段，不写即可 &apos;&apos;&apos; instance.name = validated_data.get(&quot;name&quot;,instance.name) instance.address = validated_data.get(&quot;address&quot;,instance.name) instance.phone = validated_data.get(&quot;phone&quot;,instance.name) instance.email = validated_data.get(&quot;email&quot;,instance.name) instance.save() return instance 注意：在“正向序列化”的时候，CharField字段里的参数都没有作用，只有在“反向序列化”是才会有作用。 反向序列化的操作过程：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849In [1]: from idcs.serializers import IdcSerializerIn [2]: data = &#123;&apos;id&apos;: 1,&apos;name&apos;: &apos;数北机房&apos;,&apos;address&apos;: &apos;北京数北机房&apos;,&apos;phone&apos;: &apos;12312341234&apos;,&apos;email&apos;: &apos;aaa@123.com&apos;,&apos;letter&apos;: &apos;yz&apos;&#125;In [2]: data = &#123;&apos;id&apos;: 1, ...: &apos;name&apos;: &apos;亦庄机房&apos;, ...: &apos;address&apos;: &apos;北京亦庄机房&apos;, ...: &apos;phone&apos;: &apos;12345678&apos;, ...: &apos;email&apos;: &apos;aaa@123.com&apos;, ...: &apos;letter&apos;: &apos;yz&apos;&#125; # 这里的data数据模拟前端接口传进来的数据哈In [3]: serializer = IdcSerializer(data=data) # 将Json格式的数据传入IdcSerializer进行序列化In [4]: serializer # 得到序列化后的结果Out[4]: IdcSerializer(data=&#123;&apos;id&apos;: 1, &apos;name&apos;: &apos;亦庄机房&apos;, &apos;address&apos;: &apos;北京亦庄机房&apos;, &apos;phone&apos;: &apos;12345678&apos;, &apos;email&apos;: &apos;rock@51reboot.com&apos;, &apos;letter&apos;: &apos;yz&apos;&#125;): id = IntegerField(read_only=True) name = CharField(max_length=32, required=True) address = CharField(max_length=256, required=True) phone = CharField(max_length=15, required=True) email = EmailField(required=True) letter = CharField(max_length=5, required=True)In [5]: serializer.is_valid() # 查看验证是否通过，调用的是(required=True, max_length=32)这些条件参数哈Out[5]: TrueIn [6]: serializer.validated_data # 通过validated_data获取数据Out[6]: OrderedDict([(&apos;name&apos;, &apos;亦庄机房&apos;), (&apos;address&apos;, &apos;北京亦庄机房&apos;), (&apos;phone&apos;, &apos;12345678&apos;), (&apos;email&apos;, &apos;aaa@123.com&apos;), (&apos;letter&apos;, &apos;yz&apos;)])In [7]: del data[&quot;id&quot;] # 删除id数据后方便添加到数据库中In [8]: dataOut[8]: &#123;&apos;name&apos;: &apos;亦庄机房&apos;,&apos;address&apos;: &apos;北京亦庄机房&apos;,&apos;phone&apos;: &apos;12345678&apos;,&apos;email&apos;: &apos;aaa@123.com&apos;,&apos;letter&apos;: &apos;yz&apos;&#125;In [9]: serializer = IdcSerializer(data=data) # 重新执行验证In [10]: serializer.is_valid()Out[10]: TrueIn [11]: serializer.save() # 这里的save调用了IdcSerializer类里我们写的create方法Out[11]: &lt;Idc: 亦庄机房&gt; 上面在编写IdcSerializer序列化类的时候，写了create和update方法，那么这两个方法有什么用呢？又是如何使用的呢？ 重点概念：Django能自动判断你提交的请求是需要增加，判断的标准是基于ID，如果传入的数据里有ID的话，那么认为你是需要进行修改，没有ID则认为是需要进行创建 在上面操作细节中，在执行serializer.save() 方法时，事实上是调用了IdcSerializer类的create方法，就是基于Django智能判断来实现的。 2.4、序列化总结1、正向序列化1234561. 拿到quertset2. 将quertset给序列化类 serializer = IdcSerializer(idc) serializer = IdcSerializer(Idc.objects.all(), many=True)3. 转JSON JSONRenderer().render(serializer.data) 2、反向序列化1234data = JSONRenderer().parse(content)serializer = IdcSerializer(data=data)serializer.is_valid()serializer.save() 正向序列化：从数据库里拿出来数据，然后返回Json给前端反向序列化：从前端接口拿到数据（data），将数据转换成数据流，然后序列化验证后，保存到数据库中。 本文由“Rock”布道，本站学习和整理发布。]]></content>
      <categories>
        <category>Python开发</category>
        <category>Django</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>Django</tag>
        <tag>DRF</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix系列之《自动化发现主机并添加监控》]]></title>
    <url>%2F2018%2F06%2F14%2FZabbix%E7%B3%BB%E5%88%97%E4%B9%8B%E3%80%8A%E8%87%AA%E5%8A%A8%E5%8C%96%E5%8F%91%E7%8E%B0%E4%B8%BB%E6%9C%BA%E5%B9%B6%E6%B7%BB%E5%8A%A0%E7%9B%91%E6%8E%A7%E3%80%8B.html</url>
    <content type="text"><![CDATA[前言，本文将介绍zabbix强大功能之一，自动化发现主机并将其添加到zabbix监控平台，思考一下，如果贵公司上线20台物理机或云主机，需要将这些主机添加到监控平台，如果一台一台添加的话那基础设施运维就有活干了！那本文就是介绍zabbix是如何解决这个问题的。 创建思路首先说下自动发现强大的功能，到底可以完成什么工作： 快速发现并添加主机; 简单的管理; 随着环境的改变而快速搭建监控系统; 自动发现基于网络发现功能，而网络发现又基于以下信息： IP地址段; 基于服务的FTP、SSH、Web、POP3、IMAP、TCP等; 从Zabbix-agent端接收的信息; 从SNMP agent端接受的信息; 可以理解创建自动发现的过程为，zabbix-server会扫描添加的IP地址段。比如需要添加IP地址段为192.168.80.100到192.168.80.199这个区间的机器，设定好网络区间。当zabbix-server扫描到已经启动的些机器时，下一步需要触发动作，什么类型的机器进行什么操作。比如linux机器添加linux模板，并且添加到KVM虚拟机的分组当中。当完成了这些操作，zabbix主机的添加也就已经完成了。下面先进行动作的设置。 创建动作上面简单介绍了下创建思路，有了简单的了解，那么下面来看看是如何创建的 依次点击以下位置： 配置 动作 自动发现 创建动作 填写动作位置名称，这里设置的是自动发现，当然可以设置多个动作，就像上边说的不同主机不同动作。 点击动作旁边的条件选项，下拉选择主机地址，并设置符合条件的IP地址区间段。 选择新的触发条件选择下拉框中的服务类型，在选择Zabbix客户端 点击操作 选择操作类型为：添加到主机群组 选择要添加的主机群组 先点击里面的添加 再点击外边的添加 （4和5这个步骤是zabbix的老毛病了，注意好顺序。） 此处就是外边的那个添加。 添加操作为主机选择添加主机。 添加关联模板 添加完成 创建发现规则上面的创建动作完成后，紧接着就需要创建发现规则，因为有了这个规则，才能完成一系列自动发现、自动添加监控、触发告警等动作。 点击自动发现→创建发现规则 点击主机 自动发现： 填写名称 由agent代理程序自动发现 IP范围：填写发现范围 延迟：此处按秒计算 添加检查：此处添加zabbix的uname 设备唯一性准则：按IP地址区分 最后点击启用，添加。 自动发现就添加完成了，点击到首页仪表板，在agent配置没问题的情况下，应该添加到主机了。 已经有机器被发现并自动添加到zabbix监控平台。 本文来源于作者：“祁成” 投稿，由本站整理发布，感谢作者辛勤付出。]]></content>
      <categories>
        <category>Zabbix</category>
      </categories>
      <tags>
        <tag>自动发现</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix系列之《WEB场景监控》]]></title>
    <url>%2F2018%2F06%2F14%2FZabbix%E7%B3%BB%E5%88%97%E4%B9%8B%E3%80%8AWEB%E5%9C%BA%E6%99%AF%E7%9B%91%E6%8E%A7%E3%80%8B.html</url>
    <content type="text"><![CDATA[前言：本文将带你了解Zabbix在监控日常web业务上会有哪些优异的表现。 回想一下你曾今登录JD Shopping的时候，都经历了哪些步骤呢？ 因此我进行了分析，步骤大致如下： 打开页面–&gt;登录–&gt;登录验证–&gt;退出。 在工作中，有些业务是需要监控web平台的登录是否正常，有些平台的登录认证也比较复杂，那如果做简单的监控室无法实现的。因此，我们通过下面的例子来进行模拟，监控的是本身的zabbix网站，因为zabbix本身是有用户认证功能的。 检测流程 打开网站：如果http code为200，并且响应的html中包含Zabbix SIA表示打开成功（zabbix页面有这个标示） 登陆后台：post用户名和密码到index.php，如果响应200，那表示post成功。并且通过正则表达式从响应的html中匹配sid，这个sid也就是一个宏变量，退出可以使用到 验证登陆：打开首页，检索html中是否包含Profile（只有登陆成功，才会有Profile出现，它在成功页面的右上角，一个按钮） 退出账号：传递参数sid给index.php即可退出，响应200即表示退出成功。可以使用item key来获取每个step的速度以及响应时间或者说最新的一个错误消息，自己去研究吧，不难。 创建Web scenarios 在这里填写登录zabbix的用户名密码，设定为变量。 打开首页 登录 登录验证 退出登录 保存配置全部填写完成之后记得保存 查看结果monitorning-&gt;web-&gt;筛选出你的主机-&gt;查看“zabbix性能监控”，结果如下图各个阶段的响应时间、速度、返回状态码以及总的响应时间 创建触发器系统为每个step创建了3个item，分别是DownloadSpeed页面下载速度/ResponseCode响应代码/ResponseTime响应时间，为整个Web Scenario创建了一个web.test.fail的item和一个web.test.error的item，可以分别为其创建trigger。 创建一个监控Zabbix登陆失败的触发器 创建一个监控整个web scenario所有step运行是否成功的触发器 返回值为0表示整个web scenario的所有step都执行成功了，第几步的step执行失败就返回数字几，且后续的step都不会继续执行下去。 本文来源于作者：“祁成” 投稿，由本站整理发布，感谢作者辛勤付出。]]></content>
      <categories>
        <category>Zabbix</category>
      </categories>
      <tags>
        <tag>Web</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker系列之《善用DockerHub管理自己的镜像》]]></title>
    <url>%2F2018%2F06%2F12%2FDocker%E7%B3%BB%E5%88%97%E4%B9%8B%E3%80%8A%E5%96%84%E7%94%A8DockerHub%E7%AE%A1%E7%90%86%E8%87%AA%E5%B7%B1%E7%9A%84%E9%95%9C%E5%83%8F%E3%80%8B.html</url>
    <content type="text"><![CDATA[前言：在上一篇文章里我们简单介绍了Docker Hub，这篇文章带着大家深入学习如何使用Docker开源的镜像托管仓库。对于个人制作的镜像而言，托管在Docker Hub镜像仓库上是一个非常不错的选择。 Docker Hub的官网是：https://hub.docker.com/它与同源代码托管服务的Github类似，不同的是Docker Hub提供的是镜像托管服务。利用Docker Hbu，我们可以搜索、创建、分享和管理镜像，还可以利用其提供的自动化构建技术直接在集群云服务器上构建镜像。 Docker Hub为用户提供不限数目的公开镜像托管服务，但仅提供一个私有镜像托管服务。如果需要更多的私有镜像托管，需要额外付费。 镜像的分发想要将本机创建的镜像分发到互联网提供其他用户使用，最便捷的方式就是使用Docker Hub。首先登录Docker Hub官网注册 可以使用GitHub帐号登录，请自行探索。注册成功后，在命令行登录我们刚注册的帐号： 1234567891011121314151617# docker loginLogin with your Docker ID to push and pull images from Docker Hub. If you don't have a Docker ID, head over to https://hub.docker.com to create one.Username: nicksorsPassword:Login Succeeded# cat /root/.docker/config.json # 这里是登录后的配置文件&#123; "auths": &#123; "https://index.docker.io/v1/": &#123; "auth": "bmlja3NvcnM6YWJjMTIzISE=" &#125; &#125;, "HttpHeaders": &#123; "User-Agent": "Docker-Client/18.03.1-ce (linux)" &#125;&#125; 用户名和密码通过哈希运算之后保存在auth字段，这样可以保证密码的安全性。当然，我们也可以在首次上传镜像时由Docker主动提示我们输入密码。 登录成功后，使用push命令上传镜像，如果不指定镜像TAG，指定的仓库在本地的所有镜像上都会上传到Docker Hub。下面的push将imported镜像上传到Docker Hub： 12345# docker images importedREPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZEimported container a5d0a399ea83 38 minutes ago 144.7 MBimported v1 a5d0a399ea83 38 minutes ago 144.7 MB# docker push nicksors/imported # 将本地的imported推送到docker hub上的nicksors仓库里 遇到的错误1：在上传时，必须在镜像名字前面加用户ID ，否则会出现错误信息：1Error response from daemon: You cannot push a &quot;root&quot; repository. Please rename your repository to &lt;user&gt;/&lt;repo&gt; (ex: nicksors/imported) 解决方法：12# docker tag imported:v1 nicksors/imported:v1# docker push nicksors/imported:v1 #再执行就可以了 可以看到镜像正在上传，输出信息如下：123456# docker push nicksors/imported:v1Do you really want to push to public registry? [y/n]: yThe push refers to a repository [docker.io/nicksors/imported] (len: 1)a5d0a399ea83: Pushed v1: digest: sha256:01e7412fcf2bc44191d874a6be336988cb266ebbc0b4928fc63fdbd1dc5f9733 size: 1197 上传成功后可以在Docker Hub上看到提交的镜像： 上传到公网镜像仓库的一些重要注意事项 要上传到公网镜像仓库时，要先给本地镜像打一个标签tag； 本地镜像名中要包含公网的网址和账号； 1234 $ docker tag imported:v1 docker.io/nicksors/imported:v1 然后再执行上传就可以了，$ docker push docker.io/nicksors/imported:v1 个人理解： Linux拷贝命令 cp 为例，它含两个参数，一个是源文件、另一个是目标文件，cp 源文件 目标文件 docker push 只有一个参数，要想把本地的文件上传到公网或私有仓库中，只有用docker tag 命令，给本地镜像多打一个标签，使得本地镜像包含公网或私有仓库的域名或IP地址信息，这样执行docker push 时docker 就知道将进行上传到哪里了。 怎么样，你学会如何使用Docker Hub了吗！]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>DockerHub</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker系列之《企业级私有仓库解决方案》]]></title>
    <url>%2F2018%2F06%2F11%2FDocker%E7%B3%BB%E5%88%97%E4%B9%8B%E3%80%8A%E4%BC%81%E4%B8%9A%E7%BA%A7%E7%A7%81%E6%9C%89%E4%BB%93%E5%BA%93%E8%A7%A3%E5%86%B3%E6%96%B9%E6%A1%88%E3%80%8B.html</url>
    <content type="text"><![CDATA[前言： Docker Hub作为Docker默认官方公共镜像，如果自己想搭建私有镜像仓库，官网也提供registry镜像，使得搭建私有仓库非常简单。 一、搭建私有镜像仓库:registry1.1、下载registry镜像并启动12$ docker pull registry$ docker run -d -v /opt/registry:/var/lib/registry -p 5000:5000 --restart=always --name registry registry 1.2、测试，查看镜像仓库中所有镜像12$ curl http://127.0.0.1:5000/v2/_catalog&#123;&quot;repositories&quot;:[]&#125; 1.3、私有镜像仓库管理1）配置私有仓库可信任1234567891011$ vim /etc/docker/daemon.json&#123;"insecure-registries":["127.0.0.1:5000"]&#125;systemctl restart docker这里需要注意一点，如果daemon.json里已经有配置，"需要在原有配置后面加逗号，不然失效" 譬如：$ cat /etc/docker/daemon.json&#123; "registry-mirrors": [ "https://registry.docker-cn.com"], "insecure-registries": ["172.16.194.130:5000"]&#125; 2）打标签1$ docker tag centos:6 127.0.0.1:5000/centos:7 3）上传1$ docker push 127.0.0.1:5000/centos:7 4）下载1$ docker pull 127.0.0.1:5000/centos:7 5）列出镜像标签12$ curl http://127.0.0.1:5000/v2/centos/tags/list&#123;"name":"centos","tags":["7"]&#125; 注意：127.0.0.1可以换成你网卡的地址 二、Docker Hub公共镜像仓库使用因为dockerHub是国外的服务器，push和pull操作都比较慢，甚至有连接超时的情况，个人研究玩玩还是可以的。https://cloud.docker.com/swarm/nicksors 1）注册帐号https://hub.docker.com 2）登录Docker Hub12345$ docker login或$ docker login --username=nicksors --password=xxxWARNING! Using --password via the CLI is insecure. Use --password-stdin.Login Succeeded 3）镜像打标签1$ docker tag nginx:1.12 nicksors/nginx:v2 4）上传1$ docker push nicksors/nginx:v2 5）下载1$ docker pull nicksors/nginx:v2 三、基于Harbor搭建Docker私有镜像仓库（推荐:很多企业都用这个）3.1、什么是Harbor？Harbor是VMware开源的又一个Docker Registry企业级私有仓库，其项目地址为https://github.com/vmware/harbor；相比Docker公司自己提供的Registry私有镜像仓库而言，Harbor提供了更多的功能，如下： 基于角色的访问控制 - 用户与Docker镜像仓库通过“项目”进行组织管理，一个用户可以对多个镜像仓库在同一命名空间（project）里有不同的权限。 镜像复制 - 镜像可以在多个Registry实例中复制（同步）。尤其适合于负载均衡，高可用，混合云和多云的场景。 图形化用户界面 - 用户可以通过浏览器来浏览，检索当前Docker镜像仓库，管理项目和命名空间。 AD/LDAP 支持 - Harbor可以集成企业内部已有的AD/LDAP，用于鉴权认证管理。 审计管理 - 所有针对镜像仓库的操作都可以被记录追溯，用于审计管理。 国际化 - 已拥有英文、中文、德文、日文和俄文的本地化版本。更多的语言将会添加进来。 RESTful API - RESTful API 提供给管理员对于Harbor更多的操控, 使得与其它管理软件集成变得更容易。 部署简单 - 提供在线和离线两种安装工具， 也可以安装到vSphere平台(OVA方式)虚拟设备。 以上来自官网介绍：https://vmware.github.io/harbor/cn/ 3.2、准备环境 自己创建的虚拟机：CentOS7.2、配置是2G2C； Docker版本：Docker version 18.03.0-ce Docker-compose：docker-compose version 1.20.1 Harbor版本：harbor-offline-installer-v1.4.0.tgz 3.3、安装Harbor在安装Harbor之前，必须保证你的环境已经安装好docker和docker-compose了,这两个安装方法在Docker官网都有：12安装Docker方法：https://docs.docker.com/install/linux/docker-ce/centos安装Docker-Compose方法：https://docs.docker.com/compose/install/#install-compose 你可以在 Harbor版本https://github.com/vmware/harbor/releases 地址下载你想要装的版本，这里我选择最新的1.4.0，当然你看到的时候已经不是最新版本了。123# 选择离线安装版本$ wget https://storage.googleapis.com/harbor-releases/release-1.4.0/harbor-offline-installer-v1.4.0.tgz（如果下载慢的话，你可以使用迅雷下载，有的网友就这么干，会快很多） 解压下载的包，进入解压后的harbor目录，里面有个harbor.cfg就是配置文件啦，简单说下：这里面可以配置LDAP，数据库，邮件信息，ssl证书等。12345$ vim harbor.cfg# 我配置了两个地方，主机名和Harbor admin的密码，其他默认hostname = 172.16.194.130harbor_admin_password = abc123!! 下面奉上一份harbor.cfg的关键参数说明：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145## Configuration file of Harbor#hostname设置访问地址，可以使用ip、域名，不可以设置为127.0.0.1或localhosthostname = 172.16.194.130 #这里我使用本机IP# 访问协议，默认是http，也可以设置https，如果设置https，则nginx ssl需要设置onui_url_protocol = http#Maximum number of job workers in job servicemax_job_workers = 3#Determine whether or not to generate certificate for the registry's token.#If the value is on, the prepare script creates new root cert and private key#for generating token to access the registry. If the value is off the default key/cert will be used.#This flag also controls the creation of the notary signer's cert.customize_crt = on# 指定的证书文件，生产环境一定要使用ssl证书ssl_cert = /data/cert/server.crtssl_cert_key = /data/cert/server.key# 存放证书的路径,这个路径会挂载到宿主机的/data/目录下secretkey_path = /data#Admiral's url, comment this attribute, or set its value to NA when Harbor is standaloneadmiral_url = NA#Log files are rotated log_rotate_count times before being removed. If count is 0, old versions are removed rather than rotated.log_rotate_count = 50#Log files are rotated only if they grow bigger than log_rotate_size bytes. If size is followed by k, the size is assumed to be in kilobytes.#If the M is used, the size is in megabytes, and if G is used, the size is in gigabytes. So size 100, size 100k, size 100M and size 100G#are all valid.log_rotate_size = 200M#************************BEGIN INITIAL PROPERTIES************************# 配置邮件server信息email_identity =email_server = smtp.mydomain.comemail_server_port = 25email_username = sample_admin@mydomain.comemail_password = abcemail_from = admin &lt;sample_admin@mydomain.com&gt;email_ssl = falseemail_insecure = false# 启动Harbor后，管理员UI登录的密码，默认是Harbor12345harbor_admin_password = admin123# 认证方式，这里支持多种认证方式，如LADP、本次存储、数据库认证。默认是db_auth，mysql数据库认证auth_mode = db_auth# ldap配置ldap_url = ldaps://ldap.mydomain.com#A user's DN who has the permission to search the LDAP/AD server.#If your LDAP/AD server does not support anonymous search, you should configure this DN and ldap_search_pwd.#ldap_searchdn = uid=searchuser,ou=people,dc=mydomain,dc=com#the password of the ldap_searchdn#ldap_search_pwd = password#The base DN from which to look up a user in LDAP/ADldap_basedn = ou=people,dc=mydomain,dc=com#Search filter for LDAP/AD, make sure the syntax of the filter is correct.#ldap_filter = (objectClass=person)# The attribute used in a search to match a user, it could be uid, cn, email, sAMAccountName or other attributes depending on your LDAP/ADldap_uid = uid#the scope to search for users, 0-LDAP_SCOPE_BASE, 1-LDAP_SCOPE_ONELEVEL, 2-LDAP_SCOPE_SUBTREEldap_scope = 2#Timeout (in seconds) when connecting to an LDAP Server. The default value (and most reasonable) is 5 seconds.ldap_timeout = 5#Verify certificate from LDAP serverldap_verify_cert = true#Turn on or off the self-registration featureself_registration = on#The expiration time (in minute) of token created by token service, default is 30 minutestoken_expiration = 30# 用户创建项目权限控制，默认是everyone（所有人），也可以设置为adminonly（只能管理员）project_creation_restriction = everyone#************************END INITIAL PROPERTIES************************#######Harbor DB configuration section########The address of the Harbor database. Only need to change when using external db.db_host = mysql#The password for the root user of Harbor DB. Change this before any production use.db_password = root123#The port of Harbor database hostdb_port = 3306#The user name of Harbor databasedb_user = root##### End of Harbor DB configuration########The redis server address. Only needed in HA installation.redis_url =##########Clair DB configuration#############Clair DB host address. Only change it when using an exteral DB.clair_db_host = postgres#The password of the Clair's postgres database. Only effective when Harbor is deployed with Clair.#Please update it before deployment. Subsequent update will cause Clair's API server and Harbor unable to access Clair's database.clair_db_password = password#Clair DB connect portclair_db_port = 5432#Clair DB usernameclair_db_username = postgres#Clair default databaseclair_db = postgres##########End of Clair DB configuration#############The following attributes only need to be set when auth mode is uaa_authuaa_endpoint = uaa.mydomain.orguaa_clientid = iduaa_clientsecret = secretuaa_verify_cert = trueuaa_ca_cert = /path/to/ca.pem### Docker Registry setting ####registry_storage_provider can be: filesystem, s3, gcs, azure, etc.registry_storage_provider_name = filesystem#registry_storage_provider_config is a comma separated "key: value" pairs, e.g. "key1: value, key2: value2".#Refer to https://docs.docker.com/registry/configuration/#storage for all available configuration.registry_storage_provider_config = 3.4、启动Harbor修改完配置文件后，在的当前目录执行./install.sh，Harbor服务就会根据当期目录下的docker-compose.yml开始下载依赖的镜像，检测并按照顺序依次启动各个服务。123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293$ ./install.sh[Step 0]: checking installation environment ...Note: docker version: 18.03.0Note: docker-compose version: 1.20.1[Step 1]: loading Harbor images ...Loaded image: vmware/notary-server-photon:v0.5.1-v1.4.0Loaded image: vmware/notary-signer-photon:v0.5.1-v1.4.0Loaded image: vmware/harbor-db:v1.4.0Loaded image: vmware/clair-photon:v2.0.1-v1.4.0Loaded image: vmware/postgresql-photon:v1.4.0Loaded image: vmware/harbor-adminserver:v1.4.0Loaded image: vmware/harbor-ui:v1.4.0Loaded image: vmware/harbor-log:v1.4.0Loaded image: vmware/harbor-jobservice:v1.4.0Loaded image: vmware/nginx-photon:v1.4.0Loaded image: vmware/registry-photon:v2.6.2-v1.4.0Loaded image: vmware/photon:1.0Loaded image: vmware/mariadb-photon:v1.4.0Loaded image: vmware/harbor-db-migrator:1.4[Step 2]: preparing environment ...Clearing the configuration file: ./common/config/adminserver/envClearing the configuration file: ./common/config/ui/envClearing the configuration file: ./common/config/ui/app.confClearing the configuration file: ./common/config/ui/private_key.pemClearing the configuration file: ./common/config/db/envClearing the configuration file: ./common/config/jobservice/envClearing the configuration file: ./common/config/jobservice/app.confClearing the configuration file: ./common/config/registry/config.ymlClearing the configuration file: ./common/config/registry/root.crtClearing the configuration file: ./common/config/nginx/nginx.confClearing the configuration file: ./common/config/log/logrotate.confloaded secret from file: /data/secretkeyGenerated configuration file: ./common/config/nginx/nginx.confGenerated configuration file: ./common/config/adminserver/envGenerated configuration file: ./common/config/ui/envGenerated configuration file: ./common/config/registry/config.ymlGenerated configuration file: ./common/config/db/envGenerated configuration file: ./common/config/jobservice/envGenerated configuration file: ./common/config/log/logrotate.confGenerated configuration file: ./common/config/jobservice/app.confGenerated configuration file: ./common/config/ui/app.confGenerated certificate, key file: ./common/config/ui/private_key.pem, cert file: ./common/config/registry/root.crtThe configuration files are ready, please use docker-compose to start the service.[Step 3]: checking existing instance of Harbor ...[Step 4]: starting Harbor ...Creating harbor-log ... doneCreating harbor-db ... doneCreating registry ... doneCreating harbor-adminserver ... doneCreating harbor-ui ... doneCreating nginx ... doneCreating harbor-jobservice ... done✔ ----Harbor has been installed and started successfully.----Now you should be able to visit the admin portal at http://172.16.194.130.For more details, please visit https://github.com/vmware/harbor .# 这时候你可以通过docker-compose 或docker ps来查看Harbor依赖运行的一些容器# 当然你也可以通过docker-compose来管理这些容器$ docker-compose ps Name Command State Ports-------------------------------------------------------------------------------------------------------------------------------------harbor-adminserver /harbor/start.sh Up (healthy)harbor-db /usr/local/bin/docker-entr ... Up (healthy) 3306/tcpharbor-jobservice /harbor/start.sh Up (healthy)harbor-log /bin/sh -c /usr/local/bin/ ... Up (healthy) 127.0.0.1:1514-&gt;10514/tcpharbor-ui /harbor/start.sh Up (healthy)nginx nginx -g daemon off; Up 0.0.0.0:443-&gt;443/tcp, 0.0.0.0:4443-&gt;4443/tcp, 0.0.0.0:80-&gt;80/tcpregistry /entrypoint.sh serve /etc/ ... Up (healthy) 5000/tcp$ docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESbaf9d3e586f8 vmware/harbor-jobservice:v1.4.0 "/harbor/start.sh" About an hour ago Up About an hour (healthy) harbor-jobservice484d5c4fca4b vmware/nginx-photon:v1.4.0 "nginx -g 'daemon of…" About an hour ago Up About an hour 0.0.0.0:80-&gt;80/tcp, 0.0.0.0:443-&gt;443/tcp, 0.0.0.0:4443-&gt;4443/tcp nginxdd7c62b45af1 vmware/harbor-ui:v1.4.0 "/harbor/start.sh" About an hour ago Up About an hour (healthy) harbor-uie5494bd12f64 vmware/registry-photon:v2.6.2-v1.4.0 "/entrypoint.sh serv…" About an hour ago Up About an hour (healthy) 5000/tcp registry915b753623b7 vmware/harbor-adminserver:v1.4.0 "/harbor/start.sh" About an hour ago Up About an hour (healthy) harbor-adminserver55ca16b86243 vmware/harbor-db:v1.4.0 "/usr/local/bin/dock…" About an hour ago Up About an hour (healthy) 3306/tcp harbor-db30ca0cb76dd0 vmware/harbor-log:v1.4.0 "/bin/sh -c /usr/loc…" About an hour ago Up About an hour (healthy) 127.0.0.1:1514-&gt;10514/tcp 3.5、登录Harbor启动完成后，会提示你Harbor的访问地址：http://172.16.194.130 登录界面 输入账号和我们预先设定的密码：admin/admin123 我们可以看到系统各个模块如下： 项目：新增/删除项目，查看镜像仓库，给项目添加成员、查看操作日志、复制项目等 日志：仓库各个镜像create、push、pull等操作日志 系统管理 用户管理：新增/删除用户、设置管理员等 复制管理：新增/删除从库目标、新建/删除/启停复制规则等 配置管理：认证模式、复制、邮箱设置、系统设置等 其他设置 用户设置：修改用户名、邮箱、名称信息 修改密码：修改用户密码 注意：非系统管理员用户登录，只能看到有权限的项目和日志，其他模块不可见。 3.6、向Harbor仓库中心提交私有镜像我们要尝试下能不能把自己 Docker 里面的镜像 push 到 Harbor 的 library 里来（默认这个 library 项目是公开的，所有人都可以有读的权限，都不需要 docker login 进来，就可以拉取里面的镜像）。 3.6.1、配置Docker registry仓库地址在/etc/docker/daemon.json里添加配置如下：123&#123; &quot;insecure-registries&quot;: [&quot;172.16.194.130&quot;]&#125; 配置好后，别忘了重启systemctl restart docker 3.6.2、Docker 登录Harbor为什么要登录呢？跟Docker Hub一样，你得登录才能表明你是合法用户，才能push；1234$ docker login 172.16.194.130Username: adminPassword: (这里输入harbor平台设置的admin密码)Login Succeeded 3.6.3、本地私有镜像打tag，提交到Harbor1234567891011$ docker tag tale:base 172.16.194.130/library/tale:base$ docker push 172.16.194.130/library/taleThe push refers to repository [172.16.194.130/library/tale]a3ece4722ead: Pusheded61150eb02c: Pushed0f9f3d37a459: Pushed8ed018b01f91: Pushedb17185091796: Pushedb03095563b79: Pushedbase: digest: sha256:f82f2e175479d6d232efab45f81a4495cc4ad0a48135fd839dc27fdee8c13c77 size: 1574 提交成功，我们来看看Harbor仓库里的信息 能看到已经提交到libary公共仓库中。 同理，你也可以测试下从 Harbor pull 镜像到你的 Docker 中去，操作如下：123456789$ docker rmi 172.16.194.130/library/tale:base$ docker pull 172.16.194.130/library/tale:basebase: Pulling from library/taleDigest: sha256:f82f2e175479d6d232efab45f81a4495cc4ad0a48135fd839dc27fdee8c13c77Status: Downloaded newer image for 172.16.194.130/library/tale:base$ docker images REPOSITORY TAG IMAGE ID CREATED SIZE172.16.194.130/library/tale base ab8e3ca33cd0 5 days ago 372MB 镜像在被我删除后，从Harbor里成功pull了回来。 3.7、Harbor配置ssl认证3.7.1、创建证书1$ cd /data/cert/ 1、创建 CA 根证书1$ openssl req -newkey rsa:4096 -nodes -sha256 -keyout ca.key -x509 -days 365 -out ca.crt -subj &quot;/C=CN/L=xian/O=nova/CN=harbor-registry&quot; 2、生成一个证书签名, 设置访问域名为harbor.moxiu.cn1$ openssl req -newkey rsa:4096 -nodes -sha256 -keyout harbor.moxiu.cn.key -out server.csr -subj &quot;/C=CN/L=xian/O=nova/CN=harbor.moxiu.cn&quot; 3、生成主机的证书1$ openssl x509 -req -days 365 -in server.csr -CA ca.crt -CAkey ca.key -CAcreateserial -out harbor.moxiu.cn.crt 3.7.2、配置harbor以https方式访问12345$ vim harbor.cfghostname = harbor.moxiu.cn:443ui_url_protocol = httpsssl_cert = /data/cert/harbor.moxiu.cn.crtssl_cert_key = /data/cert/harbor.moxiu.cn.key 3.7.3、配置Docker registry仓库地址在/etc/docker/daemon.json里添加配置如下：123&#123; "insecure-registries": ["harbor.moxiu.cn"]&#125; 然后，重启docker服务生效 3.7.4、登录验证1、验证admin登录方法11234$ docker login harbor.moxiu.cnUsername (admin): adminPassword: Login Succeeded 2、验证admin登录方法212$ docker login -u admin -p abc123!! harbor.moxiu.cnLogin Succeeded 3、Web页面登录验证http://harbor.moxiu.cn/harbor/sign-in用户名/密码：admin/abc123!! 因为不是有效机构颁发的证书，所有浏览器会提示不安全。如果企业需要使用，那需要买商用的证书更换即可。]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>harbor</tag>
        <tag>registry</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix系列之《监控TCP连接状态》]]></title>
    <url>%2F2018%2F06%2F08%2FZabbix%E7%B3%BB%E5%88%97%E4%B9%8B%E3%80%8A%E7%9B%91%E6%8E%A7TCP%E8%BF%9E%E6%8E%A5%E7%8A%B6%E6%80%81%E3%80%8B.html</url>
    <content type="text"><![CDATA[前言：在运维工作中，服务器的TCP连接情况一致是关注的范畴，TCP活跃连接突然增高？是什么原因导致？机器被黑了？web业务流量上来了？谁知道呢… 今天为大家介绍zabbix监控服务器的TCP连接状态，看完本文你将学到如下知识： 撰写zabbix自定义监控key和如何使用自定义脚本； 学会自己创建模板，并在模板里创建一个图表； 效果展示 服务器的TCP连接通过zabbix监控并用上面的图表呈现出来，可以横向与历史数据进行对比，一眼看出当前值是否正常。这个图表是自己创建的，下面有创建的方法。 那么我们接下来就开始学习之旅~ 客户端撰写自定义脚本我使用shell写了一个脚本，便于获取TCP的各种状态的值12345678[root@adminset ~]# sh tcp.sh total91[root@adminset ~]# sh tcp.sh ESTABLISHED41[root@adminset ~]# sh tcp.sh TIME_WAIT51[root@adminset ~]# sh tcp.sh CLOSE_WAIT0 脚本内容如下：vim tcp.sh123456789101112131415#!/bin/bash#获取各种状态连接数if [[ "$1" = "" || "$1" = "total" ]]then netstat -n |grep 'tcp'|wc -l exit 0;fistr=`netstat -n | awk '/^tcp/ &#123;++S[$NF]&#125; END &#123;for(a in S) print a, S[a]&#125;'|grep $1`if [[ "$str" = "" ]]then echo 0;else echo $str|awk '&#123;print $2&#125;'fi 把此文件存放到/usr/lib/zabbix/externalscripts/里(没有的话创建)，然后给与755权限，并修改用户与组为zabbix，同时允许zabbix用户无密码运行netstat12echo "zabbix ALL=(root) NOPASSWD:/bin/netstat"&gt;&gt;/etc/sudoerssed -i 's/^Defaults.*.requiretty/#Defaults requiretty/' /etc/sudoers #不关闭的话，会无法获取数据，并且zabbix日志里报 创建自定义key在Zabbix系列之《安装Agent客户端并添加主机监控》一文里写到zabbix_agent.conf配置文件中，Include参数包含了/etc/zabbix/zabbix_agentd.d/*.conf这个目录下所有以.conf结尾的文件。 在/etc/zabbix/zabbix_agentd.d/目录里创建tcp.conf文件，写入下面内容：12# tcp连接数UserParameter=netstat.conn[*], /usr/lib/zabbix/externalscripts/tcp.sh $1 关于zabbix 自定义key的写法，这里没法展开说明，还请善用搜索框和官网。 测试在测试前，需要重启客户端程序，加载刚添加的配置1systemctl restart zabbix-agent 我的测试结果：123456[root@adminset ~]# zabbix_get -s 172.16.194.128 -p 10050 -k "netstat.conn[total]"83[root@adminset ~]# zabbix_get -s 172.16.194.128 -p 10050 -k "netstat.conn[ESTABLISHED]"44[root@adminset ~]# zabbix_get -s 172.16.194.128 -p 10050 -k "netstat.conn[CLOSE_WAIT]"0 如果你能通过zabbix_get命令获取到值，说明你的客户端配置完全没问题了，接下来就是服务端添加监控。什么？你没有zabbix_get命令？天啦！请查看：解决方法 服务端创建模板1、创建一个名为“Template OS Netstat”的模板点击 【Configuration】–&gt;【Templates】–&gt;【Create templateImport】点击Add添加。 2、创建一个名为“Netstat”的Applications点击刚创建的模板，【Applications】–&gt;【Create application】 3、创建ITEMS(监控项)创建一个item 创建好的items上面所有的items都是一个一个加上去的，如果你要自己制作模板，就得这么干！除此之外别无他法。 4、创建Graphs（图表）点击 【Graphs】–&gt;【Create graph】 到这里，整个创建模板的过程就算完成了。 模板导入如果你嫌上面的步骤麻烦，只是想使用这个模板的话，这里提供了一种便捷的方法：我将上面制作的模板导出，并提供你下载。 请点击下载：Template OS Netstat模板，下载后在你的zabbix里导入该模板即可。 主机关联模板把需要监控的主机添加模板关联即可监控 本文讲解了如何自定义脚本和key，并且通过案例演示了创建模板的过程，以及提供创建的模板给大家，今后在工作中自己也可以尝试着做模板，一方面为了自己学习，另一方面自己做的模板给他人使用，你会有成就感。 好了，本文就到这，如果你在阅读或使用文章中遇到问题，欢迎加入QQ群：32330026，我们是一群爱学习的人，期待与你一起学习进步。]]></content>
      <categories>
        <category>Zabbix</category>
      </categories>
      <tags>
        <tag>netstat</tag>
        <tag>TCP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix系列之《安装Agent客户端并添加主机监控》]]></title>
    <url>%2F2018%2F06%2F07%2FZabbix%E7%B3%BB%E5%88%97%E4%B9%8B%E3%80%8A%E5%AE%89%E8%A3%85Agent%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%B9%B6%E6%B7%BB%E5%8A%A0%E4%B8%BB%E6%9C%BA%E7%9B%91%E6%8E%A7%E3%80%8B.html</url>
    <content type="text"><![CDATA[前言：上一片文章讲解了如何快速安装zabbix，本文将介绍安装zabbix和增加一个主机监控的细节，不足之处还望指出。 安装ZabbixAgent使用yum快速安装1yum install zabbix-agent 修改配置文件123find / -name &apos;*zabbix_agentd.conf*&apos;# /etc/zabbix/zabbix_agentd.confcp /etc/zabbix/zabbix_agentd.conf /etc/zabbix/zabbix_agentd.conf.bak 修改相关具体项123456789# vim /etc/zabbix/zabbix_agentd.confPidFile=/var/run/zabbix/zabbix_agentd.pidLogFile=/var/log/zabbix/zabbix_agentd.logLogFileSize=0Server=zabbix_server_IP zabbix服务器ip地址ServerActive=zabbix_server_IP 主动向zabbix server发送监控内容Hostname=Monitor_host agent节点的host主机名，在添加监控的时候要与这个名称一致UnsafeUserParameters=1 是否启用自定义key,zabbix监控mysql、tomcat等数据时需要自定义keyInclude=/etc/zabbix/zabbix_agentd.d/*.conf 启动客户端1# systemctl start zabbix-agent 开机自启动1# systemctl enable zabbix-agent 服务器添加被监控主机截至目前，已经安装好了zabbix server和zabbix agent，那接下来添加一台监控主机作为演示，帮助大家认识zabbix是如何监控服务器的。 登陆 http://zabbix_server_ip/zabbix, 点击 【Configuration】-&gt;【Hosts】-&gt;【Create host】 添加模板 模板添加完成后，回到Host页，然后点击页面下方的“add”按钮，即添加完成。 监控列表如下，你添加的所有主机监控，都将会在下方显示：绿色的“ZBX”字样表示已成功通过zabbix agent对其进行监控，当然还有其他方式进行监控，如SNMP方式等。 整个Dashboard监控页面显示如下显示有一个监控异常 查看图表点击【Monitoring】-&gt;【Graphs】-&gt;【Group】-&gt;【Host】-&gt; 【Graph】（可以选择你关心的查看） 到这里，我们完成了如何安装zabbix，以及部署、添加监控等信息。也有了详细的示例演示，希望能帮助你对zabbix有个初步的认识，后续文章，敬请持续关注。]]></content>
      <categories>
        <category>Zabbix</category>
      </categories>
      <tags>
        <tag>Zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix系列之《CentOS7快速安装Zabbix3-4》]]></title>
    <url>%2F2018%2F06%2F03%2FZabbix%E7%B3%BB%E5%88%97%E4%B9%8B%E3%80%8ACentOS7%E5%BF%AB%E9%80%9F%E5%AE%89%E8%A3%85Zabbix3-4%E3%80%8B.html</url>
    <content type="text"><![CDATA[前言：Zabbix系列文章是实战操作为主的文章，这个系列文章设计从入门实战到深度使用，以及后面呈现一些高阶的玩法，带领运维同学搞定企业监控。 这篇文章适合刚入行的运维同学，在运维领域学习技术最好的方式就是：先快速将它搭建起来，然后根据每个组件或知识点横向深入学习，这也是最佳实践，本文就是带领运维童鞋们快速安装和掌握监控领域的利器，zabbix！ 系统环境准备在安装zabbix之前，你需要对系统做一个简单的初始化工作，这是zabbix能否正常运行的必备条件。 关闭selinux永久关闭123# vi /etc/selinux/configSELINUX=disabledSELINUXTYPE=targeted 临时关闭1setenforce 0 关闭防火墙永久关闭12systemctl stop firewalld.service #停止firewallsystemctl disable firewalld.service #禁止firewall开机启动 临时生效1iptables -F 配置系统时间同步设置每隔20分钟同步一次1*/20 * * * * ntpdate -u asia.pool.ntp.org &gt;/dev/null 2&gt;&amp;1 选择你需要的版本进行安装你打开zabbix官网会发现，zabbix安装页面提供了非常详细的条件供你选择，能适应主流Linux发行版的需求。 如题，我使用的是CentOS7.2版本，那么我选择的最佳实践就是通过yum安装，如果你没有那么高的定制需求，建议使用此方法。当然如果有特定需求或规范，你也可以选择源码编译安装。 如上，是我选择的版本信息。 安装和初始化安装zabbix1、CentOS7的yum源里默认不能安装zabbix，这使得zabbix自己提供了一个repo源，我们需要安装下：1# rpm -i http://repo.zabbix.com/zabbix/3.4/rhel/7/x86_64/zabbix-release-3.4-2.el7.noarch.rpm 2、安装zabbix-server以及必要的一些包1# yum install zabbix-server-mysql zabbix-web-mysql 安装数据库1、CentOS7默认安装MariaDB，值得说一下的是，MariaDB与MySQL在使用上没有区别，咱们正常使用即可。 快速安装数据库：123456789101112131415161718# yum -y install mariadb mariadb-server# systemctl start mariadb# systemctl enable mariadb# 初始化数据库# mysql_secure_installation &lt;== 会有很多提示，一路回车即可# 登录数据库[root@nicksors ~]# mysqlWelcome to the MariaDB monitor. Commands end with ; or \g.Your MariaDB connection id is 412Server version: 5.5.56-MariaDB MariaDB ServerCopyright (c) 2000, 2017, Oracle, MariaDB Corporation Ab and others.Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.MariaDB [(none)]&gt; 2、创建初始数据库12345# mysql &lt;==进入数据库，并执行下面几条SQL语句mysql&gt; create database zabbix character set utf8 collate utf8_bin; &lt;==创建一个数据库，名称为zabbixmysql&gt; grant all privileges on zabbix.* to zabbix@localhost identified by 'password'; &lt;==创建用户，并设置权限和密码mysql&gt; quit; 导入初始化数据库1# zcat /usr/share/doc/zabbix-server-mysql*/create.sql.gz | mysql -uzabbix -p zabbix 给zabbix-server做一些配置1、首先你得告诉zabbix_server，你的数据库密码是什么？编辑 /etc/zabbix/zabbix_server.conf文件，修改如下：1DBPassword=123123 （我设置的密码是123123，你自己设置的多少，填写到这里） 2、配置php的时间区域编辑/etc/httpd/conf.d/zabbix.conf文件，取消下面这一行的注释1# php_value date.timezone Asia/Shanghai &lt;==如果你是中国大陆用户，请设置时间区域为“亚洲/上海” 启动zabbix_server 和zabbix_agent进程1、启动12# systemctl restart zabbix-server httpd# systemctl enable zabbix-server httpd 2、启动后保持检查的好习惯：1234[root@nicksors ~]# netstat -lntup|egrep "zabbix|http"tcp 0 0 0.0.0.0:10051 0.0.0.0:* LISTEN 23022/zabbix_servertcp6 0 0 :::80 :::* LISTEN 23205/httpdtcp6 0 0 :::10051 :::* LISTEN 23022/zabbix_server zabbix_server端口默认为10051 zabbix_agent端口默认为10050 3、访问地址为：http://server_ip_or_name/zabbix请将server_ip_or_name换成你的主机IP地址 Web页面配置zabbix点击Next step 这一步如果有“红叉”的，你需要满足，自行百度可以解决。点击Next step 默认会选择MySQL，port填写3306，Password填写你设置的密码即可。点击Next step 设置Zabbix Server信息，默认即可，Name写不写随你。点击Next step 你的配置总览。点击Next step 告诉你已经配置成功，配置文件在/etc/zabbix/web/zabbix.conf.php文件里，今后有变动需要更改配置，在这个文件更改就行。点击Finish跳转至登录页面 默认用户名密码：Admin/zabbix Zabbix Dashboard 到这里就完成了zabbix的安装部署啦，后续文章，敬请持续关注。]]></content>
      <categories>
        <category>Zabbix</category>
      </categories>
      <tags>
        <tag>Zabbix</tag>
        <tag>CentOS</tag>
      </tags>
  </entry>
</search>
